{"id":"tilt_ui-0xg","title":"Design and implement BrewSignal Recipe Format v1.0","description":"## Completed: BrewSignal Recipe Format v1.0 Specification\n\n**Status**: Specification complete, ready for review\n\n**Location**: `docs/BREWSIGNAL_RECIPE_FORMAT_V1.md`\n\n**JSON Schema**: `backend/schemas/brewsignal-recipe-v1.0.schema.json`\n\n---\n\n## Summary\n\nAfter comprehensive review by specialized agents (spec-flow-analyzer, best-practices-researcher, architecture-strategist), we determined that creating a custom format is **justified** with the following approach:\n\n### Decision: Formalize Current API Format as \"BrewSignal Recipe Format v1.0\"\n\n**Key Finding**: BrewSignal's database and API already use a **simpler format** than BeerJSON 1.0:\n- `og: 1.050` (not `{\"value\": 1.050, \"unit\": \"sg\"}`)\n- `fg: 1.012` (not verbose BeerJSON wrapping)\n- `batch_size_liters: 19.0` (direct field names)\n\n**Strategy**: \n1. **Formalize existing API format** as official BrewSignal Recipe Format v1.0\n2. **Keep BeerJSON compatibility** for imports/exports (ecosystem interop)\n3. **Add BrewSignal extensions** for fermentation-specific features\n4. **Best of both worlds**: Simple for our app, compatible with ecosystem\n\n---\n\n## Specification Highlights\n\n### Core Principles\n- **Simplicity**: Raw numbers for gravity (`1.050` not wrapped objects)\n- **Readability**: Short field names (`og`, `fg`, `abv`)\n- **Fermentation-First**: Optimized for tracking, not brew day complexity\n- **Celsius-Native**: All temps in Celsius (internal standard)\n- **Extensible**: `brewsignal_extensions` for custom features\n\n### File Format\n- **Extension**: `.brewsignal`\n- **MIME Type**: `application/vnd.brewsignal.v1+json`\n- **Encoding**: UTF-8\n\n### BrewSignal Extensions\nFermentation-specific features not in standard formats:\n\n```json\n{\n  \"brewsignal_extensions\": {\n    \"fermentation_tracking\": {\n      \"og_validation\": { \"enabled\": true, \"tolerance_sg\": 0.003 },\n      \"fg_prediction\": { \"enabled\": true, \"ml_model\": \"kalman_exponential\" },\n      \"anomaly_detection\": { \"stuck_fermentation\": true }\n    },\n    \"batch_defaults\": {\n      \"auto_link_device\": true,\n      \"temperature_control\": {\n        \"target_c\": 18.0,\n        \"hysteresis_c\": 1.0\n      }\n    }\n  }\n}\n```\n\n### Conversion to/from BeerJSON\n- Lossless round-trip conversion\n- Preserves unknown fields in extensions\n- Import: BeerXML/BeerJSON/Brewfather â†’ BrewSignal\n- Export: BrewSignal â†’ BeerJSON/BeerXML (for ecosystem compatibility)\n\n---\n\n## Implementation Status\n\n### âœ… Completed\n- [x] Full specification document (13 sections, 12 pages)\n- [x] JSON Schema for validation\n- [x] Minimal and complete recipe examples\n- [x] Conversion strategy (BeerJSON â†” BrewSignal)\n- [x] API integration plan (no breaking changes)\n\n### ğŸ”„ Next Steps (New Issues)\n- [ ] Backend validation utilities (`backend/services/brewsignal_format.py`)\n- [ ] Export endpoint (`GET /api/recipes/{id}/export?format=brewsignal`)\n- [ ] Validation endpoint (`POST /api/recipes/validate`)\n- [ ] Round-trip tests (BrewSignal â†’ BeerJSON â†’ BrewSignal)\n- [ ] Example recipes in `/examples` directory\n\n---\n\n## Review Findings\n\n### Architecture Analysis (Score: 9.20/10)\n- **Ecosystem Compatibility**: âœ… Maintains BeerJSON import/export\n- **Migration Cost**: âœ… Zero (formalizes existing format)\n- **Maintenance Burden**: âœ… 93% lower than custom-only approach\n- **User Experience**: âœ… Simple + compatible\n\n### Best Practices Research\n- BeerJSON 1.0 is verbose but stable (not actively maintained)\n- Custom format justified when:\n  - âœ… Existing simple format already in use\n  - âœ… Interop maintained via converters\n  - âœ… Domain-specific features needed (fermentation tracking)\n\n### Spec Flow Analysis\n- All critical questions answered\n- Privacy/security guidelines defined (NEVER export HA entities, calibration)\n- Validation rules specified\n- User flows documented\n\n---\n\n## Files\n\n1. **docs/BREWSIGNAL_RECIPE_FORMAT_V1.md** - Complete specification\n2. **backend/schemas/brewsignal-recipe-v1.0.schema.json** - JSON Schema for validation\n\n---\n\n## Recommendation\n\n**Close this issue** and create implementation tasks:\n- `tilt_ui-xxx`: Backend validation utilities\n- `tilt_ui-yyy`: Export endpoint\n- `tilt_ui-zzz`: Validation endpoint\n- `tilt_ui-aaa`: Example recipes\n\nOr mark as **Ready for Review** if stakeholder approval needed before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-09T18:41:26.319589488+11:00","updated_at":"2025-12-10T09:38:10.19327653+11:00","closed_at":"2025-12-10T09:38:10.19327653+11:00"}
{"id":"tilt_ui-13p","title":"Reduce redundant gravity displays on batch detail page","description":"## Problem\nThe batch detail page displays current gravity 4+ times, creating visual clutter and redundancy:\n\n1. **Live Readings Card** (top-left): Shows `1.048` with LIVE badge and temperature\n2. **Fermentation Card Hero**: Large `1.048` with FERMENTING badge  \n3. **Timeline Progress Bar**: `CURRENT FG 1.048` as third point\n4. **ML Predictions Card**: `(now: 1.048)` next to Predicted FG\n\n## Screenshot Reference\nSee batch detail page - gravity 1.048 appears at least 4 times in different cards.\n\n## Design Options\n\n### Option A: Remove Live Readings Card (Recommended)\n- Merge live reading timestamp into Fermentation Card\n- Fermentation Card hero already shows current SG prominently\n- Temperature can move to Timeline card or small indicator\n\n### Option B: Consolidate Timeline\n- Remove \"Current FG\" point from OGâ†’Targetâ†’Current timeline\n- Keep timeline as OG â†’ Target FG only (2 points)\n- Current SG is already in hero display\n\n### Option C: Simplify ML Predictions  \n- Remove `(now: X)` from ML Predictions card\n- Users can compare Predicted FG with Current SG shown above\n- Keeps ML card focused on predictions, not current state\n\n## Recommendation\nImplement Option A + C:\n- Remove Live Readings Card entirely\n- Add \"Updated Xs ago\" to Fermentation Card\n- Remove \"(now: X)\" from ML Predictions\n\n## Acceptance Criteria\n- [ ] Current gravity displayed max 2 times (hero + timeline OR just hero)\n- [ ] No loss of information (temp, update time still accessible)\n- [ ] Cleaner, less cluttered batch detail page\n- [ ] Mobile layout still works well\n\n## Files to Modify\n- `frontend/src/routes/batches/[id]/+page.svelte` - Remove LiveReadingsCard import/usage\n- `frontend/src/lib/components/batch/BatchFermentationCard.svelte` - Add update timestamp\n- `frontend/src/lib/components/batch/MLPredictions.svelte` - Remove \"(now: X)\"\n- Possibly delete `frontend/src/lib/components/batch/BatchLiveReadingsCard.svelte`\n\n## Design Considerations\n- The Live Readings card provides quick glanceability of \"device is connected and sending data\"\n- Consider keeping device connection status indicator somewhere\n- Temperature display needs a home if Live Readings card is removed","status":"closed","priority":2,"issue_type":"task","owner":"hugh@hughtec.com","created_at":"2026-01-16T12:25:27.857557483+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-16T12:33:50.779153421+11:00","closed_at":"2026-01-16T12:33:50.779153421+11:00","close_reason":"Consolidated batch detail UI - redesigned fermentation card with proper progress visualization, removed redundant Live Readings card, cleaned up ML Predictions"}
{"id":"tilt_ui-1w4","title":"Integrate ML Pipeline with Main Application","description":"The ML pipeline is complete and tested (PR #61) but not yet integrated with the main application. This issue tracks connecting the ML components to the live reading pipeline.\n\n**Current State:**\nâœ… Complete:\n- ML pipeline implementation in backend/ml/\n- 48/48 tests passing\n- Per-device state isolation\n- Kalman filtering, anomaly detection, curve fitting, MPC\n\nâŒ Not Connected:\n- Not called from backend/main.py reading handler\n- Not exposed via API endpoints\n- Not displayed in frontend UI\n- State lost on service restart\n\n**Proposed Integration:**\n\nPhase 1: Basic Integration\n1. Add MLPipelineManager to backend/main.py\n2. Process readings through ML pipeline in handle_tilt_reading()\n3. Broadcast ML results via WebSocket\n4. Display filtered values on dashboard\n\nPhase 2: State Persistence\n5. Hydrate ML state from database on startup (last 48 hours)\n6. Ensures predictions work immediately after restart\n7. Option: Store ML results in new ml_results table\n\nPhase 3: UI Integration\n8. Show Kalman-filtered values on dashboard\n9. Display FG predictions and completion estimates\n10. Anomaly alerts (stuck fermentation, temperature spikes)\n11. MPC temperature trajectory visualization\n\n**Acceptance Criteria:**\n- ML pipeline processes all live Tilt readings\n- Filtered values broadcast via WebSocket\n- ML state survives service restarts\n- Dashboard shows filtered SG/temp\n- Predictions visible on batch detail page\n- Anomaly alerts displayed to user\n- No performance degradation (\u003c10ms overhead)\n\n**GitHub Issue:** #62","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-09T19:54:47.785215585+11:00","updated_at":"2025-12-09T20:21:17.845011679+11:00","closed_at":"2025-12-09T20:21:17.845011679+11:00"}
{"id":"tilt_ui-2s1","title":"Fix FG validator field-order dependency","description":"FG validator uses @field_validator which can be bypassed if fields are in wrong order. Use @model_validator(mode='after') instead. See todo 001.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-10T11:32:02.013332577+11:00","updated_at":"2025-12-10T11:36:27.248911871+11:00","closed_at":"2025-12-10T11:36:27.248911871+11:00"}
{"id":"tilt_ui-34j","title":"Fermentation Notes and Event Logging","description":"## Summary\nAdd the ability to attach timestamped notes and events to batches. Includes both manual user notes and automatic system-generated events, displayed as a timeline alongside fermentation data.\n\n## Motivation\nBrewing is iterative - you learn from each batch. Notes let brewers document what they did, what happened, and what they'd do differently. This institutional memory compounds over time and completes the batch record beyond just readings.\n\n## Features\n\n### 1. Manual Notes\nUser-entered observations at any time during fermentation:\n- \"Dry hopped 2oz Citra\"\n- \"Raised temp for diacetyl rest\"\n- \"Krausen falling, fermentation slowing\"\n- \"Tasted sample - still too sweet\"\n\n### 2. Automatic Events\nSystem-generated entries for significant occurrences:\n- Batch status transitions (\"Started fermenting\", \"Moved to conditioning\")\n- Temperature target changes (\"Target changed: 65Â°F â†’ 68Â°F\")\n- Control events (\"Heater turned ON\", \"Cooler turned OFF\")\n- Anomalies detected (\"Temperature spike detected\")\n- Readings milestones (\"OG recorded: 1.055\", \"FG reached: 1.012\")\n- Device events (\"Device went offline\", \"Device reconnected\")\n\n### 3. Timeline View\nChronological display of all events:\n- Integrated with fermentation chart (markers on timeline)\n- Expandable list view with full details\n- Filter by event type (user notes, system events, anomalies)\n- Search within notes\n\n## Database Schema\n\n```python\nclass BatchEvent(Base):\n    __tablename__ = \"batch_events\"\n    \n    id = Column(Integer, primary_key=True)\n    batch_id = Column(Integer, ForeignKey(\"batches.id\"), nullable=False)\n    timestamp = Column(DateTime, default=datetime.utcnow, nullable=False)\n    event_type = Column(String(50), nullable=False)\n    # Types: \"note\", \"status_change\", \"temp_change\", \"control\", \n    #        \"anomaly\", \"milestone\", \"device\"\n    \n    title = Column(String(200), nullable=False)  # Short summary\n    content = Column(Text)  # Full details (optional)\n    metadata = Column(JSON)  # Structured data (e.g., old/new values)\n    \n    # For linking to specific readings or devices\n    reading_id = Column(Integer, ForeignKey(\"readings.id\"), nullable=True)\n    device_id = Column(String(50), nullable=True)\n    \n    created_by = Column(String(50))  # \"user\" or \"system\"\n\n# Index for efficient queries\nIndex('idx_batch_events_batch_timestamp', BatchEvent.batch_id, BatchEvent.timestamp)\n```\n\n## API Endpoints\n\n```python\n# Create user note\nPOST /api/batches/{batch_id}/events\n{\n    \"title\": \"Dry hopped\",\n    \"content\": \"Added 2oz Citra pellets\",\n    \"event_type\": \"note\"\n}\n\n# Get all events for batch\nGET /api/batches/{batch_id}/events\nGET /api/batches/{batch_id}/events?type=note  # Filter by type\nGET /api/batches/{batch_id}/events?since=2024-01-01  # Filter by date\n\n# Update note (user notes only)\nPUT /api/batches/{batch_id}/events/{event_id}\n\n# Delete note (user notes only)\nDELETE /api/batches/{batch_id}/events/{event_id}\n```\n\n## Automatic Event Integration Points\n\n### Temperature Controller (`temp_controller.py`)\n```python\n# When target changes\nawait create_event(batch_id, \"temp_change\", \n    title=f\"Target: {old}Â°C â†’ {new}Â°C\",\n    metadata={\"old_target\": old, \"new_target\": new})\n\n# When heater/cooler activates\nawait create_event(batch_id, \"control\",\n    title=f\"Heater turned {'ON' if state else 'OFF'}\",\n    metadata={\"entity\": entity_id, \"state\": state})\n```\n\n### Batch Status Changes (`routers/batches.py`)\n```python\n# On status transition\nawait create_event(batch_id, \"status_change\",\n    title=f\"Status: {old_status} â†’ {new_status}\")\n```\n\n### ML Pipeline (anomaly detection)\n```python\n# When anomaly detected\nawait create_event(batch_id, \"anomaly\",\n    title=f\"Anomaly: {anomaly_reasons[0]}\",\n    metadata={\"score\": anomaly_score, \"reasons\": anomaly_reasons})\n```\n\n## Frontend Components\n\n### NotesPanel.svelte\n- Textarea for adding new notes\n- List of existing notes/events\n- Edit/delete for user notes\n- Distinct styling for user vs system events\n\n### EventTimeline.svelte\n- Vertical timeline component\n- Markers for each event\n- Expandable event details\n- Integration with chart (hover to highlight)\n\n### ChartEventMarkers.svelte\n- Vertical lines/markers on uPlot chart\n- Click to see event details\n- Different colors by event type\n\n## UI Design\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Batch: American IPA #12                                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  [Chart with gravity/temp curves and event markers]          â”‚\nâ”‚       â”‚    â”‚         â”‚                    â”‚                  â”‚\nâ”‚       â–¼    â–¼         â–¼                    â–¼                  â”‚\nâ”‚      OG  Tempâ†‘    Dry hop              FG stable             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Notes \u0026 Events                              [+ Add Note]    â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  ğŸ“ Jan 15, 2:30 PM - Dry hopped with 2oz Citra             â”‚\nâ”‚  ğŸ”§ Jan 14, 8:00 AM - Target: 65Â°F â†’ 68Â°F (diacetyl rest)   â”‚\nâ”‚  âš ï¸ Jan 12, 3:15 PM - Temperature spike detected (+5Â°F)     â”‚\nâ”‚  ğŸŸ¢ Jan 10, 6:00 PM - Started fermenting (OG: 1.065)        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Implementation Phases\n1. **Phase 1**: Database model, API endpoints, basic notes UI\n2. **Phase 2**: Automatic events from temp controller and batch status\n3. **Phase 3**: Timeline view and chart integration\n4. **Phase 4**: Anomaly and milestone event generation\n\n## Estimated Effort\n15-25 hours total\n\n## Success Criteria\n- Users can add notes in \u003c 3 clicks\n- All significant system events are automatically logged\n- Events display alongside chart for context\n- Notes persist and are searchable\n- Mobile-friendly note entry","status":"open","priority":2,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:28:10.649201848+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:28:10.649201848+11:00"}
{"id":"tilt_ui-3q7","title":"Add yeast strain database for batch customization and ML enhancement","description":"## Overview\nPopulate database with known brewery yeast strains from public sources:\n- https://www.brewunited.com/yeast_database.php\n- https://beermaverick.com/yeasts/\n\n## Benefits\n1. **Batch flexibility** - Allow changing yeast on a batch when substituting (e.g., recipe calls for one yeast but using another)\n2. **ML enhancement** - Yeast strain data (attenuation range, temp range, flocculation) could improve fermentation predictions\n3. **Better recipe accuracy** - Track actual yeast used vs recipe yeast\n\n## Data to capture per strain\n- Lab/manufacturer (Wyeast, White Labs, Safale, etc.)\n- Strain name and ID\n- Attenuation range (min/max %)\n- Temperature range (min/max)\n- Flocculation (low/medium/high)\n- Alcohol tolerance\n- Description/flavor notes\n\n## UI Changes\n- Yeast dropdown on batch edit form\n- Search/filter by lab, style compatibility\n- Show yeast details on batch detail page\n\n## Implementation\n- Scrape/import yeast data from sources\n- Create Yeast model and migration\n- Link batches to yeast (separate from recipe yeast)\n- Expose yeast data to ML pipeline","status":"closed","priority":2,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-16T13:36:04.199562583+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-16T14:06:26.586681725+11:00","closed_at":"2026-01-16T14:06:26.586681725+11:00","close_reason":"Implemented yeast strain database with 223 strains from BrewUnited, YeastSelector component, and batch integration"}
{"id":"tilt_ui-40f","title":"Add recipe export endpoint with format selection","description":"Add API endpoint to export recipes in multiple formats (BrewSignal, BeerJSON, BeerXML).\n\n## Endpoint\n`GET /api/recipes/{id}/export`\n\n## Query Parameters\n- `format`: \"brewsignal\" (default), \"beerjson\", \"beerxml\", \"brewfather\"\n- `include_extensions`: true/false (include BrewSignal extensions, default: true)\n\n## Response Headers\n- `Content-Type`: Format-specific MIME type\n  - BrewSignal: `application/vnd.brewsignal.v1+json`\n  - BeerJSON: `application/json`\n  - BeerXML: `application/xml`\n- `Content-Disposition`: `attachment; filename=\"{recipe-name}-{date}.{ext}\"`\n\n## Implementation\n\n### Router (`backend/routers/recipes.py`)\n\n```python\n@router.get(\"/{id}/export\")\nasync def export_recipe(\n    id: int,\n    format: str = \"brewsignal\",\n    include_extensions: bool = True,\n    db: AsyncSession = Depends(get_db)\n):\n    # Fetch recipe with all relationships\n    recipe = await get_recipe_with_relationships(db, id)\n    \n    # Convert to requested format\n    if format == \"brewsignal\":\n        data = recipe_to_brewsignal(recipe, include_extensions)\n        content_type = \"application/vnd.brewsignal.v1+json\"\n        filename = f\"{sanitize_filename(recipe.name)}-{date.today()}.brewsignal\"\n    elif format == \"beerjson\":\n        data = recipe_to_beerjson(recipe)\n        content_type = \"application/json\"\n        filename = f\"{sanitize_filename(recipe.name)}-{date.today()}.json\"\n    # ... other formats\n    \n    return Response(\n        content=json.dumps(data, indent=2),\n        media_type=content_type,\n        headers={\"Content-Disposition\": f'attachment; filename=\"{filename}\"'}\n    )\n```\n\n## Tasks\n- [ ] Add export endpoint to recipes router\n- [ ] Implement BrewSignal format export\n- [ ] Implement BeerJSON format export (reuse existing serializer)\n- [ ] Implement BeerXML format export (future - optional)\n- [ ] Add filename sanitization (remove special chars)\n- [ ] Add proper Content-Type headers\n- [ ] Add Content-Disposition with smart filename\n\n## Testing\n- [ ] Test export for each format\n- [ ] Test filename generation (special chars, dates)\n- [ ] Test include_extensions flag\n- [ ] Test with recipes that have/don't have extensions\n- [ ] Verify Content-Type headers\n- [ ] Verify downloadable file in browser\n\n## Dependencies\n- Requires: tilt_ui-4hu (validation utilities)\n\n## Acceptance Criteria\n- Export BrewSignal format with proper MIME type\n- Export BeerJSON format (existing functionality)\n- Generate clean filenames (no special chars)\n- Include/exclude extensions based on flag\n- Download works in browser (Content-Disposition header)","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-10T09:35:14.301788965+11:00","updated_at":"2025-12-10T09:35:14.301788965+11:00","dependencies":[{"issue_id":"tilt_ui-40f","depends_on_id":"tilt_ui-4hu","type":"blocks","created_at":"2025-12-10T09:37:59.545063582+11:00","created_by":"daemon","metadata":"{}"}]}
{"id":"tilt_ui-4hu","title":"Backend validation utilities for BrewSignal Recipe Format v1.0","description":"Create backend utilities for validating and working with BrewSignal Recipe Format v1.0.\n\n## Location\n`backend/services/brewsignal_format.py`\n\n## Tasks\n\n### Validation\n- [ ] `validate_brewsignal_recipe(data: dict) -\u003e ValidationResult`\n  - Load JSON Schema from `backend/schemas/brewsignal-recipe-v1.0.schema.json`\n  - Validate using jsonschema library\n  - Return validation errors with field paths\n  - Check for warnings (unusual values)\n\n### Conversion Helpers\n- [ ] `beerjson_to_brewsignal(beerjson: dict) -\u003e dict`\n  - Unwrap BeerJSON unit objects to raw values\n  - Map field names (original_gravity â†’ og)\n  - Extract extensions from _extensions.brewsignal\n  \n- [ ] `brewsignal_to_beerjson(brewsignal: dict) -\u003e dict`\n  - Wrap values in unit objects\n  - Map field names back (og â†’ original_gravity)\n  - Preserve extensions in _extensions.brewsignal\n\n### Model Integration\n- [ ] Add property methods to `Recipe` model in `backend/models.py`:\n  - `@property brewsignal_extensions(self) -\u003e dict`\n  - `@property fermentation_tracking_config(self) -\u003e dict`\n  - `@property batch_defaults(self) -\u003e dict`\n  - `@property yeast_management_config(self) -\u003e dict`\n\n## Dependencies\n- jsonschema library (already in requirements)\n- Specification: `docs/BREWSIGNAL_RECIPE_FORMAT_V1.md`\n- Schema: `backend/schemas/brewsignal-recipe-v1.0.schema.json`\n\n## Testing\n- [ ] Unit tests for validation (valid/invalid recipes)\n- [ ] Round-trip tests (BeerJSON â†’ BrewSignal â†’ BeerJSON)\n- [ ] Test with example recipes in `examples/recipes/`\n\n## Acceptance Criteria\n- Validation catches all schema violations\n- Conversion preserves all data (lossless round-trip)\n- Model properties provide easy access to extensions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T09:34:56.074862127+11:00","updated_at":"2025-12-10T10:15:20.299499424+11:00","closed_at":"2025-12-10T10:15:20.299499424+11:00"}
{"id":"tilt_ui-4lw","title":"Health Monitoring Dashboard","description":"## Summary\nCreate a comprehensive system health page showing operational status without requiring SSH access. Critical for headless Raspberry Pi deployments where users need visibility into system state.\n\n## Motivation\nMost users run BrewSignal on a headless Pi in their garage/basement. When something stops working, they currently need to SSH in and check journalctl. A health dashboard makes troubleshooting accessible from any browser and builds trust through transparency.\n\n## Health Metrics to Display\n\n### 1. BLE Adapter Status\n- Adapter detected: Yes/No\n- Adapter name and address\n- Last successful BLE scan timestamp\n- Scan error count (last hour)\n- Active device count\n\n### 2. Device Connectivity\nFor each paired device:\n- Last reading timestamp\n- Time since last reading (with color coding)\n- Expected interval vs actual\n- Connection quality trend (for BLE devices)\n\n### 3. Home Assistant Connection\n- Connection status: Connected/Disconnected/Not configured\n- Last successful API call\n- Last failed API call (if any) with error\n- Heater/cooler entity states\n\n### 4. System Resources\n- Memory usage (used/total, percentage)\n- Disk usage (used/total, percentage)\n- CPU usage (current, 5-min average)\n- System uptime\n- Service uptime (time since last restart)\n\n### 5. Database Health\n- Database file size\n- Total reading count\n- Readings per day (recent average)\n- Oldest/newest reading timestamps\n- Last aggregation run (if implemented)\n\n### 6. Background Tasks\n- Scanner status: Running/Stopped/Error\n- Temperature controller: Running/Stopped\n- Cleanup service: Last run, next scheduled\n- WebSocket connections: Active count\n\n### 7. Network\n- Listening interfaces and ports\n- WebSocket connection count\n- Recent API request count\n\n## Technical Approach\n\n### Backend\nNew `/api/system/health` endpoint returning comprehensive status:\n\n```python\n@router.get(\"/api/system/health\")\nasync def get_system_health():\n    return {\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"ble\": {\n            \"adapter_found\": scanner.adapter_available(),\n            \"adapter_name\": scanner.adapter_name(),\n            \"last_scan\": scanner.last_scan_time(),\n            \"scan_errors_1h\": scanner.error_count_last_hour(),\n            \"status\": \"healthy\" | \"degraded\" | \"error\"\n        },\n        \"devices\": {\n            device_id: {\n                \"last_reading\": timestamp,\n                \"seconds_since_reading\": int,\n                \"expected_interval\": int,\n                \"status\": \"online\" | \"stale\" | \"offline\"\n            }\n        },\n        \"home_assistant\": {\n            \"configured\": bool,\n            \"connected\": bool,\n            \"last_success\": timestamp,\n            \"last_error\": {\"time\": timestamp, \"message\": str} | None\n        },\n        \"system\": {\n            \"memory_percent\": float,\n            \"memory_used_mb\": float,\n            \"memory_total_mb\": float,\n            \"disk_percent\": float,\n            \"disk_used_gb\": float,\n            \"disk_total_gb\": float,\n            \"cpu_percent\": float,\n            \"uptime_seconds\": int,\n            \"service_uptime_seconds\": int\n        },\n        \"database\": {\n            \"size_mb\": float,\n            \"reading_count\": int,\n            \"readings_per_day\": float,\n            \"oldest_reading\": timestamp,\n            \"newest_reading\": timestamp\n        },\n        \"tasks\": {\n            \"scanner\": \"running\" | \"stopped\" | \"error\",\n            \"temp_controller\": \"running\" | \"stopped\",\n            \"websocket_connections\": int\n        }\n    }\n```\n\n### Frontend\nNew `/system/health` page with:\n- Card-based layout for each subsystem\n- Color-coded status indicators (green/yellow/red)\n- Auto-refresh every 30 seconds\n- Manual refresh button\n- Expandable sections for details\n- Historical uptime graph (optional, phase 2)\n\n### Dependencies\n- `psutil` for system metrics (already in requirements)\n- Scanner methods for BLE status (may need additions)\n- HA client methods for connection status\n\n## UI Design\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  System Health                              Last updated: 5s â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\nâ”‚  â”‚ ğŸŸ¢ BLE       â”‚  â”‚ ğŸŸ¢ Home Asst â”‚  â”‚ ğŸŸ¡ Devices   â”‚       â”‚\nâ”‚  â”‚ Healthy      â”‚  â”‚ Connected    â”‚  â”‚ 1 stale     â”‚       â”‚\nâ”‚  â”‚ Last: 5s ago â”‚  â”‚ Last: 2m ago â”‚  â”‚ 2 online    â”‚       â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\nâ”‚                                                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\nâ”‚  â”‚ System       â”‚  â”‚ Database     â”‚  â”‚ Tasks        â”‚       â”‚\nâ”‚  â”‚ RAM: 45%     â”‚  â”‚ 125 MB       â”‚  â”‚ Scanner: âœ“   â”‚       â”‚\nâ”‚  â”‚ Disk: 23%    â”‚  â”‚ 1.2M reads   â”‚  â”‚ TempCtl: âœ“   â”‚       â”‚\nâ”‚  â”‚ CPU: 12%     â”‚  â”‚ 30 days      â”‚  â”‚ WS: 3 conn   â”‚       â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Implementation Phases\n1. **Phase 1**: Backend health endpoint with core metrics\n2. **Phase 2**: Frontend health dashboard page\n3. **Phase 3**: Device connectivity details\n4. **Phase 4**: Historical health tracking (optional)\n\n## Estimated Effort\n25-35 hours total\n\n## Success Criteria\n- Users can diagnose common issues without SSH\n- Health status updates within 30 seconds of changes\n- Clear visual distinction between healthy/degraded/error states\n- Mobile-friendly layout for checking from phone","status":"open","priority":2,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:28:09.636432602+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:28:09.636432602+11:00"}
{"id":"tilt_ui-50q","title":"Bug: Batch views sometimes unresponsive or return 500 errors","description":"## Description\nBatch views (create/edit) are sometimes unresponsive or return 500 errors. The issue is intermittent.\n\n## Steps to Reproduce\n1. Navigate to batch pages\n2. Try to create or edit batches\n3. Sometimes get no response or 500 errors\n\n## Expected Behavior\n- Batch create/edit should work reliably\n- Should return proper error messages if validation fails\n\n## Actual Behavior\n- Intermittent failures\n- 500 server errors\n- Unresponsive UI\n\n## Investigation Plan\n- Use Playwright MCP to test batch workflows\n- Check browser console for errors\n- Analyze network requests for failures\n- Review backend logs for error traces","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-09T21:01:12.557372504+11:00","updated_at":"2025-12-09T21:06:44.932862383+11:00","closed_at":"2025-12-09T21:06:44.932862383+11:00"}
{"id":"tilt_ui-87t","title":"Implement thermal model learning for MPC","description":"Query historical readings and heater/cooler states to learn thermal model parameters for each batch.\n\n**Data needed:**\n- temp_history (from readings.temp_calibrated or temp_filtered)\n- time_history (from readings.timestamp)\n- heater_history (from control_events or batch heater state)\n- cooler_history (from control_events or batch cooler state)\n- ambient_history (from ambient_readings)\n\n**Learning trigger:**\n- Learn model once when MPC first used for batch (if enough history exists)\n- Optionally re-learn periodically (e.g., every 6 hours)\n\n**Location:** backend/temp_controller.py (new helper function)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:18.286190407+11:00","updated_at":"2025-12-09T23:11:30.263186473+11:00","closed_at":"2025-12-09T23:11:30.263186473+11:00"}
{"id":"tilt_ui-8o5","title":"Add diverse example recipes in BrewSignal format","description":"Create a collection of example recipes showcasing different styles and BrewSignal format features.\n\n## Goal\nProvide real-world recipe examples for:\n- Testing validation and conversion\n- Documentation and demos\n- User reference\n- Different brewing styles\n\n## Recipe Collection\n\n### 1. `pilsner.brewsignal` - Lager Example\n- **Style**: Czech Pilsner\n- **Features**:\n  - Lager yeast with temp ranges\n  - Multi-stage fermentation (primary â†’ diacetyl rest â†’ lagering)\n  - Simple grain bill\n  - Noble hops\n  - Extensions: temperature control defaults\n\n### 2. `imperial-stout.brewsignal` - High Gravity Example\n- **Style**: Imperial Stout\n- **Features**:\n  - High OG (1.090+)\n  - Complex grain bill (6+ malts)\n  - Multiple yeast strains (future: multi-yeast support)\n  - Long fermentation schedule\n  - Extensions: FG prediction, high attenuation warnings\n\n### 3. `hazy-ipa.brewsignal` - Modern IPA\n- **Style**: New England IPA\n- **Features**:\n  - Heavy dry hopping (multiple additions)\n  - Whirlpool/hopstand additions with temps\n  - Flaked adjuncts (oats, wheat)\n  - Extensions: anomaly detection for oxidation\n\n### 4. `sour-berliner-weisse.brewsignal` - Kettle Sour\n- **Style**: Berliner Weisse\n- **Features**:\n  - Lactobacillus souring step\n  - Low IBU\n  - Simple grain bill\n  - Fruit additions (misc ingredients)\n  - Extensions: pH monitoring (future)\n\n### 5. `extract-amber-ale.brewsignal` - Extract Recipe\n- **Style**: American Amber Ale\n- **Features**:\n  - Extract brewing (no mash)\n  - Liquid/dry malt extract\n  - Specialty grains (steeping)\n  - Beginner-friendly\n  - No extensions (simple recipe)\n\n### 6. `session-ipa.brewsignal` - Low ABV Example\n- **Style**: Session IPA\n- **Features**:\n  - Low OG (~1.045)\n  - High IBU for style (50+)\n  - Hop-forward but drinkable\n  - Quick fermentation (7 days)\n\n## File Structure\n```\nexamples/recipes/\nâ”œâ”€â”€ README.md (updated with new recipes)\nâ”œâ”€â”€ minimal-pale-ale.brewsignal (existing)\nâ”œâ”€â”€ west-coast-ipa-complete.brewsignal (existing)\nâ”œâ”€â”€ pilsner.brewsignal (new)\nâ”œâ”€â”€ imperial-stout.brewsignal (new)\nâ”œâ”€â”€ hazy-ipa.brewsignal (new)\nâ”œâ”€â”€ sour-berliner-weisse.brewsignal (new)\nâ”œâ”€â”€ extract-amber-ale.brewsignal (new)\nâ””â”€â”€ session-ipa.brewsignal (new)\n```\n\n## Recipe Requirements\n\nEach recipe must:\n- [ ] Validate against JSON Schema\n- [ ] Include realistic OG/FG/ABV values\n- [ ] Use actual hop varieties and malts\n- [ ] Include appropriate yeast for style\n- [ ] Add style-specific notes\n- [ ] Demonstrate at least one BrewSignal extension\n- [ ] Include fermentation schedule where relevant\n- [ ] Use proper timing objects for hops\n\n## BrewSignal Extensions to Showcase\n\n### Fermentation Tracking\n- **Pilsner**: Temperature control for lagering\n- **Imperial Stout**: FG prediction for high gravity\n- **Hazy IPA**: Anomaly detection for oxidation\n\n### Batch Defaults\n- **All recipes**: Auto-link device when creating batch\n- **Pilsner**: Multi-stage temp control defaults\n- **Session IPA**: Quick turnaround settings\n\n### Yeast Management\n- **Imperial Stout**: High pitch rate requirement\n- **Pilsner**: Starter calculation\n- **Extract Amber**: Dry yeast rehydration\n\n## Testing\n- [ ] Validate all new recipes against schema\n- [ ] Test import via API\n- [ ] Verify conversions (BrewSignal â†” BeerJSON)\n- [ ] Check for typos and formatting\n\n## Documentation\n- [ ] Update `examples/recipes/README.md` with:\n  - New recipe descriptions\n  - Style coverage matrix\n  - Feature showcase table\n  - Brewing method coverage (All Grain, Extract, BIAB)\n\n## Acceptance Criteria\n- 6+ diverse recipes covering major styles\n- All recipes validate successfully\n- Each recipe demonstrates different features\n- README updated with recipe descriptions\n- Recipes importable via API","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-10T09:36:58.36071642+11:00","updated_at":"2025-12-10T09:36:58.36071642+11:00"}
{"id":"tilt_ui-8we","title":"Fix unbounded text fields DoS vulnerability","description":"Notes field has no max_length, allows 100+ MB DoS payloads. Add max_length=10_000 constraint. See todo 003.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-10T11:32:15.855508678+11:00","updated_at":"2025-12-10T11:36:27.254251369+11:00","closed_at":"2025-12-10T11:36:27.254251369+11:00"}
{"id":"tilt_ui-8xe","title":"Bug: Batch device selection shows unpaired Tilt instead of paired GravityMon","description":"## Description\nWhen creating a new batch, the device dropdown shows a single unpaired Tilt device instead of showing the paired GravityMon device.\n\n## Steps to Reproduce\n1. Pair a GravityMon device (visible in /devices)\n2. Ensure zero Tilt devices are paired\n3. Start to plan a new batch\n4. Check device dropdown\n\n## Expected Behavior\n- Should show paired GravityMon device\n- Should NOT show unpaired Tilt devices\n\n## Actual Behavior\n- Shows single unpaired Tilt device\n- GravityMon not visible in dropdown\n\n## Possible Causes\n- Device filtering logic not checking paired status\n- Query excluding non-Tilt device types\n- Frontend device list not including all device types","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-09T20:53:12.026094986+11:00","updated_at":"2025-12-09T20:55:49.354647889+11:00","closed_at":"2025-12-09T20:55:49.354647889+11:00"}
{"id":"tilt_ui-91a","title":"Push Notifications for Critical Events","description":"## Summary\nImplement a notification system that alerts users via browser push notifications when their fermentation needs attention. This transforms BrewSignal from passive monitoring to active alerting.\n\n## Motivation\nCurrently users must actively check the dashboard to know what's happening. With notifications, the system reaches out when action is needed - the difference between a tool you check and a system that watches for you.\n\n## Notification Triggers\n- **Temperature out of range** - Temp outside target Â± hysteresis for X minutes\n- **Fermentation complete** - FG stable (ML prediction reached)\n- **Device offline** - No reading received for X minutes (configurable per device type)\n- **Anomaly detected** - ML pipeline flags unusual readings\n- **Pitch ready** - Pre-pitch chilling target reached\n- **Batch milestone** - Status transitions (started fermenting, conditioning, etc.)\n\n## Technical Approach\n\n### Backend\n1. New `NotificationService` class in `/backend/services/notifications.py`\n2. Web Push with VAPID keys (py-vapid + pywebpush libraries)\n3. Notification preference storage in database\n4. Integration points in temp_controller, ingest_manager, batch status transitions\n5. Rate limiting to prevent notification spam (max 1 per trigger type per hour)\n\n### Database Schema\n```python\nclass NotificationSubscription(Base):\n    id: int\n    endpoint: str  # Web Push endpoint URL\n    p256dh_key: str\n    auth_key: str\n    created_at: datetime\n\nclass NotificationPreference(Base):\n    id: int\n    subscription_id: int\n    trigger_type: str  # \"temp_alert\", \"fermentation_complete\", etc.\n    enabled: bool\n    threshold_minutes: int  # For temp alerts, offline detection\n\nclass NotificationLog(Base):\n    id: int\n    subscription_id: int\n    trigger_type: str\n    batch_id: int (nullable)\n    device_id: str (nullable)\n    sent_at: datetime\n    payload: JSON\n```\n\n### Frontend\n1. Notification preferences page (`/settings/notifications`)\n2. Web Push subscription flow with permission request\n3. Service worker for receiving push events\n4. Toast notifications for in-app alerts\n5. Bell icon in header showing unread notification count\n\n### API Endpoints\n- POST /api/notifications/subscribe - Register push subscription\n- DELETE /api/notifications/subscribe - Unsubscribe\n- GET /api/notifications/preferences - Get notification settings\n- PUT /api/notifications/preferences - Update settings\n- GET /api/notifications/history - Recent notifications sent\n\n## User Flow\n1. User visits Settings \u003e Notifications\n2. Browser prompts for notification permission\n3. User configures which alerts they want (checkboxes with thresholds)\n4. System monitors fermentation and sends push when triggers fire\n5. User receives browser notification even when tab is closed\n\n## Implementation Phases\n1. **Phase 1**: Backend notification service + Web Push infrastructure\n2. **Phase 2**: Temperature and offline alerts\n3. **Phase 3**: ML-based alerts (completion, anomaly)\n4. **Phase 4**: Preferences UI and notification history\n\n## Estimated Effort\n40-60 hours total across all phases\n\n## Success Criteria\n- Users receive notifications within 30 seconds of trigger\n- Notification preferences persist across sessions\n- Works on desktop Chrome/Firefox/Edge and mobile browsers\n- Rate limiting prevents notification fatigue","status":"open","priority":1,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:28:04.852880725+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:28:04.852880725+11:00"}
{"id":"tilt_ui-a6v","title":"Add recipe validation endpoint","description":"Add API endpoint to validate recipe data before import/creation.\n\n## Endpoint\n`POST /api/recipes/validate`\n\n## Request Body\n```json\n{\n  \"format\": \"brewsignal\",\n  \"data\": { /* recipe data */ }\n}\n```\n\n## Response (Valid)\n```json\n{\n  \"valid\": true,\n  \"warnings\": [\n    {\n      \"field\": \"recipe.boil_time_minutes\",\n      \"value\": 180,\n      \"warning\": \"Unusual boil time of 180 minutes\"\n    }\n  ]\n}\n```\n\n## Response (Invalid)\n```json\n{\n  \"valid\": false,\n  \"errors\": [\n    {\n      \"field\": \"recipe.og\",\n      \"value\": 1.250,\n      \"error\": \"Value 1.250 exceeds maximum 1.200\"\n    },\n    {\n      \"field\": \"recipe.yeast.temp_min_c\",\n      \"value\": \"cold\",\n      \"error\": \"Expected number, got string\"\n    }\n  ],\n  \"warnings\": []\n}\n```\n\n## Implementation\n\n### Router (`backend/routers/recipes.py`)\n\n```python\nclass RecipeValidationRequest(BaseModel):\n    format: str  # \"brewsignal\", \"beerjson\", \"beerxml\"\n    data: dict\n\nclass ValidationError(BaseModel):\n    field: str\n    value: Any\n    error: str\n\nclass ValidationWarning(BaseModel):\n    field: str\n    value: Optional[Any] = None\n    warning: str\n\nclass RecipeValidationResponse(BaseModel):\n    valid: bool\n    errors: list[ValidationError] = []\n    warnings: list[ValidationWarning] = []\n\n@router.post(\"/validate\", response_model=RecipeValidationResponse)\nasync def validate_recipe(request: RecipeValidationRequest):\n    errors = []\n    warnings = []\n    \n    # Schema validation\n    if request.format == \"brewsignal\":\n        validation_result = validate_brewsignal_recipe(request.data)\n        errors.extend(validation_result.errors)\n    \n    # Business logic validation\n    if request.data.get(\"recipe\", {}).get(\"og\"):\n        og = request.data[\"recipe\"][\"og\"]\n        fg = request.data[\"recipe\"].get(\"fg\")\n        if fg and fg \u003e= og:\n            errors.append({\n                \"field\": \"recipe.fg\",\n                \"value\": fg,\n                \"error\": f\"FG ({fg}) must be less than OG ({og})\"\n            })\n    \n    # Warnings for unusual values\n    boil_time = request.data.get(\"recipe\", {}).get(\"boil_time_minutes\")\n    if boil_time and boil_time \u003e 120:\n        warnings.append({\n            \"field\": \"recipe.boil_time_minutes\",\n            \"value\": boil_time,\n            \"warning\": f\"Unusual boil time of {boil_time} minutes\"\n        })\n    \n    return {\n        \"valid\": len(errors) == 0,\n        \"errors\": errors,\n        \"warnings\": warnings\n    }\n```\n\n## Validation Rules\n\n### Schema Validation\n- JSON Schema validation (types, ranges, required fields)\n- Field format validation (ISO dates, etc.)\n\n### Business Logic Validation\n- [ ] FG must be less than OG\n- [ ] ABV calculation matches OG/FG (within tolerance)\n- [ ] Fermentable percentages sum to ~100% (warning if not)\n- [ ] Hop alpha acids in valid range (0-20%)\n- [ ] Yeast temp ranges valid (min \u003c max)\n- [ ] Fermentation step temperatures in valid range\n\n### Warnings (Not Errors)\n- [ ] Unusual boil time (\u003c 30 or \u003e 120 minutes)\n- [ ] Very high/low OG (\u003c 1.030 or \u003e 1.100)\n- [ ] Very high IBU (\u003e 100)\n- [ ] Very high ABV (\u003e 12%)\n- [ ] Missing recommended fields (batch_size, efficiency)\n\n## Tasks\n- [ ] Add validation endpoint to recipes router\n- [ ] Implement Pydantic request/response models\n- [ ] Schema validation (reuse from tilt_ui-4hu)\n- [ ] Business logic validation rules\n- [ ] Warning detection for unusual values\n- [ ] Error message formatting (user-friendly)\n\n## Testing\n- [ ] Test valid BrewSignal recipe (no errors, no warnings)\n- [ ] Test invalid recipe (schema violations)\n- [ ] Test business logic errors (FG \u003e= OG)\n- [ ] Test warnings (unusual values)\n- [ ] Test with example recipes\n- [ ] Test error message clarity\n\n## Dependencies\n- Requires: tilt_ui-4hu (validation utilities)\n\n## Acceptance Criteria\n- Returns valid=true for valid recipes\n- Returns clear error messages for invalid recipes\n- Detects business logic errors (FG \u003e= OG)\n- Provides helpful warnings for unusual values\n- Works with all supported formats (BrewSignal, BeerJSON)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-10T09:35:38.520086132+11:00","updated_at":"2026-01-05T10:06:23.526642407+11:00","closed_at":"2026-01-05T10:06:23.526642407+11:00","close_reason":"Added validation endpoint and tests","dependencies":[{"issue_id":"tilt_ui-a6v","depends_on_id":"tilt_ui-4hu","type":"blocks","created_at":"2025-12-10T09:37:59.550640694+11:00","created_by":"daemon","metadata":"{}"}]}
{"id":"tilt_ui-a6z","title":"Automated Database Backup System","description":"## Summary\nImplement scheduled SQLite database backups with configurable retention and rotation. Provides peace of mind and disaster recovery capability for users' fermentation data.\n\n## Motivation\nUsers accumulate months or years of fermentation data - batch history, recipes, calibration settings. A corrupted or lost database means losing that history. Automated backups are standard practice for any data-storing application.\n\n## Features\n\n### 1. Scheduled Backups\n- Configurable schedule (default: daily at 2 AM)\n- Backup on service startup\n- Manual backup trigger via UI/API\n\n### 2. Backup Rotation\n- Keep N most recent backups (default: 7)\n- Optional weekly/monthly retention\n- Automatic cleanup of old backups\n\n### 3. Backup Storage\n- Local backup directory (default: /opt/brewsignal/data/backups/)\n- Optional remote backup (future: S3, Google Drive, etc.)\n- Compression (gzip) to save space\n\n### 4. Backup Verification\n- Integrity check after backup (SQLite pragma integrity_check)\n- Size verification (not empty)\n- Optional test restore to temp location\n\n### 5. Restore Capability\n- List available backups\n- Restore from selected backup\n- Preview restore (show what would change)\n\n## Technical Approach\n\n### Backup Service\n```python\nclass BackupService:\n    def __init__(self, db_path: str, backup_dir: str, config: BackupConfig):\n        self.db_path = db_path\n        self.backup_dir = backup_dir\n        self.config = config\n    \n    async def create_backup(self) -\u003e BackupResult:\n        \"\"\"Create a new database backup.\"\"\"\n        timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n        backup_name = f\"fermentation_{timestamp}.db.gz\"\n        backup_path = os.path.join(self.backup_dir, backup_name)\n        \n        # Use SQLite backup API for consistency\n        async with aiosqlite.connect(self.db_path) as source:\n            # Create backup using SQLite's built-in backup\n            async with aiosqlite.connect(backup_path + \".tmp\") as dest:\n                await source.backup(dest)\n        \n        # Compress\n        with open(backup_path + \".tmp\", 'rb') as f_in:\n            with gzip.open(backup_path, 'wb') as f_out:\n                shutil.copyfileobj(f_in, f_out)\n        \n        os.remove(backup_path + \".tmp\")\n        \n        # Verify backup\n        if not await self.verify_backup(backup_path):\n            raise BackupError(\"Backup verification failed\")\n        \n        # Cleanup old backups\n        await self.cleanup_old_backups()\n        \n        return BackupResult(path=backup_path, size=os.path.getsize(backup_path))\n    \n    async def verify_backup(self, backup_path: str) -\u003e bool:\n        \"\"\"Verify backup integrity.\"\"\"\n        # Decompress to temp file\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            with gzip.open(backup_path, 'rb') as f_in:\n                shutil.copyfileobj(f_in, tmp)\n            tmp_path = tmp.name\n        \n        try:\n            async with aiosqlite.connect(tmp_path) as db:\n                result = await db.execute(\"PRAGMA integrity_check\")\n                row = await result.fetchone()\n                return row[0] == \"ok\"\n        finally:\n            os.remove(tmp_path)\n    \n    async def cleanup_old_backups(self):\n        \"\"\"Remove backups beyond retention limit.\"\"\"\n        backups = sorted(glob.glob(os.path.join(self.backup_dir, \"*.db.gz\")))\n        while len(backups) \u003e self.config.retention_count:\n            os.remove(backups.pop(0))\n    \n    async def list_backups(self) -\u003e List[BackupInfo]:\n        \"\"\"List available backups with metadata.\"\"\"\n        backups = []\n        for path in glob.glob(os.path.join(self.backup_dir, \"*.db.gz\")):\n            stat = os.stat(path)\n            backups.append(BackupInfo(\n                name=os.path.basename(path),\n                path=path,\n                size_mb=stat.st_size / 1024 / 1024,\n                created_at=datetime.fromtimestamp(stat.st_mtime)\n            ))\n        return sorted(backups, key=lambda b: b.created_at, reverse=True)\n    \n    async def restore_backup(self, backup_name: str):\n        \"\"\"Restore database from backup.\"\"\"\n        backup_path = os.path.join(self.backup_dir, backup_name)\n        \n        # Create backup of current DB before restore\n        await self.create_backup()\n        \n        # Decompress backup\n        with gzip.open(backup_path, 'rb') as f_in:\n            with open(self.db_path + \".restore\", 'wb') as f_out:\n                shutil.copyfileobj(f_in, f_out)\n        \n        # Swap databases\n        os.rename(self.db_path, self.db_path + \".old\")\n        os.rename(self.db_path + \".restore\", self.db_path)\n        os.remove(self.db_path + \".old\")\n```\n\n### Scheduled Task\n```python\n# In main.py lifespan\nasync def backup_scheduler():\n    while True:\n        # Calculate time until next backup\n        now = datetime.now()\n        next_backup = now.replace(hour=2, minute=0, second=0)\n        if now \u003e= next_backup:\n            next_backup += timedelta(days=1)\n        \n        await asyncio.sleep((next_backup - now).total_seconds())\n        \n        try:\n            result = await backup_service.create_backup()\n            logger.info(f\"Backup created: {result.path} ({result.size_mb:.1f} MB)\")\n        except Exception as e:\n            logger.error(f\"Backup failed: {e}\")\n```\n\n### API Endpoints\n```python\n@router.get(\"/api/system/backups\")\nasync def list_backups():\n    return await backup_service.list_backups()\n\n@router.post(\"/api/system/backups\")\nasync def create_backup():\n    return await backup_service.create_backup()\n\n@router.post(\"/api/system/backups/{name}/restore\")\nasync def restore_backup(name: str):\n    await backup_service.restore_backup(name)\n    return {\"status\": \"restored\", \"message\": \"Please restart the service\"}\n\n@router.delete(\"/api/system/backups/{name}\")\nasync def delete_backup(name: str):\n    await backup_service.delete_backup(name)\n```\n\n### Configuration\n```python\nclass BackupConfig:\n    enabled: bool = True\n    schedule_hour: int = 2  # 2 AM\n    retention_count: int = 7  # Keep 7 daily backups\n    backup_on_startup: bool = True\n    compression: bool = True\n```\n\n## UI Design\nSystem \u003e Backups page:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Database Backups                                            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Schedule: Daily at 2:00 AM              [Create Backup Now] â”‚\nâ”‚  Retention: 7 backups                    [Settings]          â”‚\nâ”‚                                                              â”‚\nâ”‚  Available Backups:                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚  â”‚ fermentation_20240115_020000.db.gz   â”‚ 45.2 MB â”‚ Today  â”‚â”‚\nâ”‚  â”‚                                       [Restore] [Delete] â”‚â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚\nâ”‚  â”‚ fermentation_20240114_020000.db.gz   â”‚ 44.8 MB â”‚ 1d ago â”‚â”‚\nâ”‚  â”‚                                       [Restore] [Delete] â”‚â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                              â”‚\nâ”‚  Total backup size: 312 MB                                   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Implementation Phases\n1. **Phase 1**: Basic backup creation and scheduling\n2. **Phase 2**: Backup listing and manual trigger\n3. **Phase 3**: Restore functionality\n4. **Phase 4**: UI and configuration\n\n## Estimated Effort\n15-20 hours total\n\n## Success Criteria\n- Backups created automatically on schedule\n- Old backups cleaned up per retention policy\n- Users can restore from any backup\n- Backup integrity verified automatically\n- Clear UI for backup management","status":"open","priority":3,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:30:35.610228045+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:30:35.610228045+11:00"}
{"id":"tilt_ui-c7s","title":"Fix percentage scale ambiguity in conversion","description":"Percentage conversion logic 'if value \u003c= 1' is ambiguous for 1.0. Always convert with validation instead. See todo 004.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-10T11:32:22.892295926+11:00","updated_at":"2025-12-10T11:36:27.25455782+11:00","closed_at":"2025-12-10T11:36:27.25455782+11:00"}
{"id":"tilt_ui-crx","title":"Enhance recipe CRUD frontend with better UX","description":"Current recipe CRUD frontend is minimal and functional but could be improved with:\n- Better form validation and error messages\n- Ingredient list display and editing (fermentables, hops, yeasts)\n- Richer recipe detail view with all BeerJSON fields\n- Batch size conversion tools (L/gal)\n- Temperature unit conversion display (C/F)\n- Recipe cloning/duplication\n- Recipe search and filtering\n- Style guide integration\n- Print/export functionality\n\nCurrent implementation covers basic recipe metadata (name, author, style, OG, FG, ABV, IBU, color, batch size, notes) but BeerJSON import includes much more detail that isn't exposed in the UI yet.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-09T19:50:26.932820447+11:00","updated_at":"2025-12-09T19:50:26.932820447+11:00"}
{"id":"tilt_ui-dvg","title":"Fix negative fermentation progress percentage","description":"## Problem\nWhen current gravity is slightly higher than OG at the start of fermentation (common before CO2 starts escaping), the progress calculation returns negative percentages like -4%.\n\n## Root Cause\n`backend/routers/batches.py:419` calculates:\n```python\ncurrent_drop = og - current_sg  # = 1.047 - 1.048 = -0.001\npercent_complete = min(100, (current_drop / total_drop) * 100)  # = -2.86%\n```\nOnly clamps maximum (100%) but not minimum (0%).\n\n## Expected Behavior\nProgress should be clamped to 0-100% range. Negative progress is not meaningful to users.\n\n## Fix\nChange line 419 to:\n```python\nprogress[\"percent_complete\"] = round(max(0, min(100, (current_drop / total_drop) * 100)), 1)\n```\n\n## Acceptance Criteria\n- [ ] Progress never shows negative values\n- [ ] Progress bar displays 0% when current SG \u003e= OG\n- [ ] Backend returns 0 instead of negative for percent_complete\n- [ ] No regression: progress still calculates correctly during active fermentation\n\n## Files to Modify\n- `backend/routers/batches.py` (line ~419)\n\n## Testing\n1. Start batch with current SG slightly above measured OG\n2. Verify progress shows 0% (not negative)\n3. Verify progress increases as SG drops below OG","status":"closed","priority":1,"issue_type":"bug","owner":"hugh@hughtec.com","created_at":"2026-01-16T12:25:10.795065396+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-16T12:26:31.6364949+11:00","closed_at":"2026-01-16T12:26:31.6364949+11:00","close_reason":"Fixed by clamping percent_complete and sg_remaining to 0 minimum. Deployed and verified."}
{"id":"tilt_ui-exb","title":"Data Lifecycle Management (Aggregation + Indexing)","description":"## Summary\nImplement comprehensive data lifecycle management to ensure long-term performance and sustainability. Includes database indexing, reading aggregation/downsampling, and configurable retention policies.\n\n## Motivation\nA single Tilt sends readings every 5 seconds = 17,280 readings/day = 6.3 million/year. Without aggregation, the database grows unbounded, queries slow, and the system becomes unusable. This is essential infrastructure for any time-series system.\n\n## Components\n\n### 1. Database Index Optimization\nAdd indexes on frequently-queried columns for immediate performance improvement.\n\n```sql\nCREATE INDEX idx_readings_timestamp ON readings(timestamp);\nCREATE INDEX idx_readings_device_id ON readings(device_id);\nCREATE INDEX idx_readings_batch_id ON readings(batch_id);\nCREATE INDEX idx_readings_device_timestamp ON readings(device_id, timestamp);\nCREATE INDEX idx_batch_notes_batch_id ON batch_notes(batch_id);\n```\n\n### 2. Reading Aggregation Service\nCompress old readings into hourly/daily averages while preserving recent detail.\n\n**Strategy:**\n- Raw readings: Keep for configurable period (default 7 days)\n- Hourly aggregates: Keep for 90 days\n- Daily aggregates: Keep indefinitely\n\n**Aggregated Reading Schema:**\n```python\nclass ReadingAggregate(Base):\n    __tablename__ = \"reading_aggregates\"\n    \n    id: int\n    device_id: str\n    batch_id: int (nullable)\n    period_start: datetime  # Hour or day boundary\n    period_type: str  # \"hourly\" or \"daily\"\n    \n    # Aggregated values\n    sg_avg: float\n    sg_min: float\n    sg_max: float\n    temp_avg: float\n    temp_min: float\n    temp_max: float\n    reading_count: int\n    \n    # Preserve ML outputs\n    avg_confidence: float\n    anomaly_count: int\n```\n\n**Aggregation Process:**\n1. Background task runs daily (configurable)\n2. Find readings older than raw retention threshold\n3. Group by device_id, batch_id, hour/day\n4. Calculate aggregates (avg, min, max, count)\n5. Insert into aggregates table\n6. Delete original raw readings\n7. Log aggregation stats\n\n### 3. Retention Policy Configuration\nUI for managing data lifecycle settings.\n\n**Settings:**\n- Raw reading retention: 7 days (default)\n- Hourly aggregate retention: 90 days (default)  \n- Daily aggregate retention: Forever (default)\n- Aggregation schedule: Daily at 3 AM (configurable)\n\n### 4. Storage Monitoring\nTrack and display database health metrics.\n\n**Metrics:**\n- Total database size (MB)\n- Reading count (raw vs aggregated)\n- Oldest/newest reading timestamps\n- Storage growth rate\n- Estimated time until disk full (if applicable)\n\n### 5. Query Layer Updates\nUpdate chart queries to transparently use aggregated data for older time ranges.\n\n```python\nasync def get_readings_for_chart(device_id: str, start: datetime, end: datetime):\n    # Recent data: use raw readings\n    if start \u003e datetime.utcnow() - timedelta(days=7):\n        return await get_raw_readings(device_id, start, end)\n    \n    # Older data: use appropriate aggregates\n    if start \u003e datetime.utcnow() - timedelta(days=90):\n        return await get_hourly_aggregates(device_id, start, end)\n    \n    return await get_daily_aggregates(device_id, start, end)\n```\n\n## Technical Approach\n\n### Backend\n1. Migration to add indexes (immediate, low-risk)\n2. New `ReadingAggregate` model\n3. `AggregationService` class with scheduled task\n4. Update reading query functions to use aggregates\n5. Storage metrics endpoint\n\n### Frontend\n1. Data management section on System page\n2. Retention policy configuration form\n3. Storage usage visualization\n4. \"Run aggregation now\" button for manual trigger\n5. Aggregation history/logs view\n\n### API Endpoints\n- GET /api/system/storage - Database size and stats\n- GET /api/system/retention - Current retention settings\n- PUT /api/system/retention - Update retention settings\n- POST /api/system/aggregate - Trigger manual aggregation\n- GET /api/system/aggregation-history - Recent aggregation runs\n\n## Implementation Phases\n1. **Phase 1**: Database indexes (immediate win)\n2. **Phase 2**: Aggregation service and schema\n3. **Phase 3**: Query layer updates for transparent aggregation\n4. **Phase 4**: UI for configuration and monitoring\n\n## Estimated Effort\n30-40 hours total\n\n## Success Criteria\n- Chart queries for 30-day range complete in \u003c 500ms\n- Database size growth rate reduced by 90%+\n- Users can configure retention without editing files\n- Historical data remains accessible via aggregates\n- Zero data loss during aggregation process","status":"open","priority":1,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:28:08.06153133+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:28:08.06153133+11:00"}
{"id":"tilt_ui-gas","title":"Batch Comparison View","description":"## Summary\nAllow users to overlay multiple batches on the same chart to compare fermentation trajectories. Helps brewers identify patterns, learn from successful batches, and improve their process over time.\n\n## Motivation\nBrewers want to compare batches to understand what worked and what didn't. \"Why did batch #5 ferment faster than #3?\" or \"How does this IPA compare to last year's?\" Currently requires exporting data and using external tools.\n\n## Features\n\n### 1. Batch Selection\n- Multi-select interface to choose 2-4 batches\n- Filter by recipe, style, yeast, date range\n- Quick select: \"Compare similar recipes\" or \"Compare same yeast\"\n\n### 2. Aligned Comparison Chart\n- Overlay gravity curves on same chart\n- Align by fermentation start (not calendar date)\n- Different colors per batch with legend\n- Optional temperature overlay\n\n### 3. Statistics Comparison\nSide-by-side metrics table:\n- OG, FG, ABV, attenuation\n- Days to reach FG\n- Average fermentation temp\n- Peak fermentation rate\n\n### 4. Insights\nHighlight differences:\n- \"Batch #5 reached FG 2 days faster\"\n- \"Batch #3 had higher peak fermentation rate\"\n- \"Temperature was 3Â°F higher in batch #5\"\n\n## Technical Approach\n\n### Backend\n```python\n@router.get(\"/api/batches/compare\")\nasync def compare_batches(batch_ids: List[int] = Query(...)):\n    \"\"\"Return aligned reading data for comparison.\"\"\"\n    batches = await get_batches_with_readings(batch_ids)\n    \n    # Align readings by time since fermentation start\n    aligned_data = []\n    for batch in batches:\n        start_time = batch.started_at or batch.created_at\n        readings = [\n            {\n                \"hours_since_start\": (r.timestamp - start_time).total_seconds() / 3600,\n                \"sg\": r.sg,\n                \"temp\": r.temp,\n                \"sg_rate\": r.sg_rate\n            }\n            for r in batch.readings\n        ]\n        aligned_data.append({\n            \"batch_id\": batch.id,\n            \"name\": batch.name,\n            \"recipe_name\": batch.recipe.name if batch.recipe else None,\n            \"readings\": readings,\n            \"stats\": calculate_batch_stats(batch)\n        })\n    \n    return aligned_data\n```\n\n### Frontend\n\n**BatchCompare.svelte** - Main comparison page\n```svelte\n\u003cscript\u003e\nlet selectedBatches = [];\nlet comparisonData = null;\n\nasync function loadComparison() {\n    const ids = selectedBatches.map(b =\u003e b.id).join(',');\n    comparisonData = await fetch(`/api/batches/compare?batch_ids=${ids}`);\n}\n\u003c/script\u003e\n\n\u003cBatchSelector bind:selected={selectedBatches} max={4} /\u003e\n\u003cbutton on:click={loadComparison}\u003eCompare\u003c/button\u003e\n\n{#if comparisonData}\n    \u003cComparisonChart data={comparisonData} /\u003e\n    \u003cStatsTable data={comparisonData} /\u003e\n{/if}\n```\n\n**ComparisonChart.svelte** - Multi-series uPlot chart\n- X-axis: Hours since fermentation start\n- Y-axis: Specific gravity\n- Multiple series with distinct colors\n- Hover shows all batch values at that point\n\n### UI Flow\n1. Navigate to Batches \u003e Compare (new tab/page)\n2. Select batches from list with checkboxes\n3. Click \"Compare Selected\"\n4. View overlaid charts and stats table\n5. Optional: Save comparison as favorite\n\n## UI Design\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Compare Batches                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Selected: IPA #12, IPA #8, IPA #5            [Compare]     â”‚\nâ”‚                                                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚  â”‚  Gravity Over Time (aligned)                            â”‚â”‚\nâ”‚  â”‚  1.065 â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚â”‚\nâ”‚  â”‚            â•²â”‚â•²                                           â”‚â”‚\nâ”‚  â”‚             â”‚ â•² â”€â”€ IPA #12 (blue)                       â”‚â”‚\nâ”‚  â”‚             â”‚  â•²â”€â”€ IPA #8 (green)                       â”‚â”‚\nâ”‚  â”‚             â”‚   â•²â”€ IPA #5 (orange)                      â”‚â”‚\nâ”‚  â”‚  1.010 â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚â”‚\nâ”‚  â”‚           0d    2d    4d    6d    8d    10d             â”‚â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                              â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\nâ”‚  â”‚            â”‚  IPA #12   â”‚  IPA #8    â”‚  IPA #5    â”‚      â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚\nâ”‚  â”‚ OG         â”‚  1.065     â”‚  1.062     â”‚  1.064     â”‚      â”‚\nâ”‚  â”‚ FG         â”‚  1.012     â”‚  1.014     â”‚  1.011     â”‚      â”‚\nâ”‚  â”‚ ABV        â”‚  6.9%      â”‚  6.3%      â”‚  7.0%      â”‚      â”‚\nâ”‚  â”‚ Days to FG â”‚  8         â”‚  10        â”‚  7         â”‚      â”‚\nâ”‚  â”‚ Avg Temp   â”‚  67Â°F      â”‚  65Â°F      â”‚  68Â°F      â”‚      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Implementation Phases\n1. **Phase 1**: Basic comparison page with batch selection\n2. **Phase 2**: Aligned multi-series chart\n3. **Phase 3**: Statistics comparison table\n4. **Phase 4**: Filtering and saved comparisons\n\n## Estimated Effort\n25-35 hours total\n\n## Success Criteria\n- Users can compare up to 4 batches simultaneously\n- Charts align by fermentation start for fair comparison\n- Clear visual distinction between batches\n- Key metrics displayed side-by-side\n- Works on mobile (responsive)","status":"open","priority":2,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:30:34.361796242+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:30:34.361796242+11:00"}
{"id":"tilt_ui-hgv","title":"Initialize MPC controller in temp_controller.py","description":"Create MPCTemperatureController instances and manage their lifecycle in the temperature control loop.\n\n**Approach:**\n- One MPC instance per batch (stored in dict similar to _batch_heater_states)\n- Initialize on first control check for batch\n- Clean up when batch leaves fermenting/conditioning\n\n**Location:** backend/temp_controller.py (add _batch_mpc_controllers dict)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:17.397976768+11:00","updated_at":"2025-12-09T23:11:30.262626673+11:00","closed_at":"2025-12-09T23:11:30.262626673+11:00"}
{"id":"tilt_ui-hhr","title":"BLE Scanner Watchdog and Auto-Recovery","description":"## Summary\nImplement a watchdog system that monitors BLE scanner health and automatically recovers from hangs, adapter failures, and other common BLE issues on Linux/Raspberry Pi.\n\n## Motivation\nBLE adapters on Linux (especially Raspberry Pi) are notoriously unreliable. They can hang, lose connection, or stop responding without clear errors. Users currently need to SSH in and restart the service manually. A watchdog provides hands-off reliability.\n\n## Common BLE Failure Modes\n1. **Adapter hang** - bluez stops responding, no readings received\n2. **Adapter disconnection** - USB adapter physically disconnects/reconnects\n3. **D-Bus timeout** - Communication with bluetoothd times out\n4. **Scan stuck** - Scanning starts but never returns results\n5. **Permission issues** - Capabilities lost after sleep/resume\n\n## Watchdog Features\n\n### 1. Health Monitoring\nTrack scanner health metrics:\n- Time since last successful reading\n- Time since last successful scan cycle\n- Error count in last hour\n- Adapter presence/status\n\n### 2. Failure Detection\nDetect issues based on:\n- No readings for paired devices in X minutes (configurable, default 10 min)\n- Repeated scan errors (\u003e5 in 5 minutes)\n- Adapter not found\n- D-Bus connection failures\n\n### 3. Recovery Actions (Graduated)\nProgressive recovery attempts:\n\n**Level 1: Soft Reset**\n- Stop and restart scanner task\n- Clear internal state\n- Retry scanning\n\n**Level 2: Adapter Reset**\n- Power cycle bluetooth adapter via hciconfig\n- `hciconfig hci0 down \u0026\u0026 hciconfig hci0 up`\n- Wait for adapter to reinitialize\n\n**Level 3: Bluetooth Service Reset**\n- Restart bluetoothd service\n- `systemctl restart bluetooth`\n- Wait for D-Bus to reconnect\n\n**Level 4: USB Reset (if applicable)**\n- Reset USB port for USB adapters\n- Use usb_modeswitch or unbind/rebind\n\n**Level 5: Alert User**\n- If all recovery fails, notify user\n- Log detailed diagnostics\n- Suggest manual intervention\n\n### 4. Configurable Thresholds\n```python\nclass WatchdogConfig:\n    reading_timeout_minutes: int = 10  # No reading = potentially stuck\n    error_threshold: int = 5  # Errors before escalating\n    recovery_cooldown_minutes: int = 5  # Min time between recovery attempts\n    max_recovery_attempts: int = 3  # Before alerting user\n```\n\n## Technical Approach\n\n### Backend Implementation\n\n**WatchdogService class:**\n```python\nclass BLEWatchdog:\n    def __init__(self, scanner: TiltScanner, config: WatchdogConfig):\n        self.scanner = scanner\n        self.config = config\n        self.last_reading_time = {}\n        self.recovery_attempts = 0\n        self.last_recovery_time = None\n    \n    async def check_health(self) -\u003e HealthStatus:\n        \"\"\"Called every minute by background task.\"\"\"\n        \n        # Check for paired devices that should be reporting\n        paired_devices = await self.get_paired_devices()\n        for device in paired_devices:\n            last_reading = self.last_reading_time.get(device.id)\n            if last_reading:\n                minutes_since = (datetime.utcnow() - last_reading).seconds / 60\n                if minutes_since \u003e self.config.reading_timeout_minutes:\n                    return HealthStatus.DEGRADED\n        \n        # Check scanner error rate\n        if self.scanner.error_count_last_hour \u003e self.config.error_threshold:\n            return HealthStatus.DEGRADED\n        \n        return HealthStatus.HEALTHY\n    \n    async def attempt_recovery(self, level: int):\n        \"\"\"Execute recovery action for given level.\"\"\"\n        if level == 1:\n            await self.soft_reset()\n        elif level == 2:\n            await self.adapter_reset()\n        elif level == 3:\n            await self.service_reset()\n        elif level == 4:\n            await self.usb_reset()\n        else:\n            await self.alert_user()\n    \n    async def adapter_reset(self):\n        \"\"\"Power cycle the BLE adapter.\"\"\"\n        subprocess.run([\"hciconfig\", \"hci0\", \"down\"], check=True)\n        await asyncio.sleep(2)\n        subprocess.run([\"hciconfig\", \"hci0\", \"up\"], check=True)\n        await asyncio.sleep(5)\n```\n\n**Integration with main.py:**\n```python\n# In lifespan\nwatchdog = BLEWatchdog(scanner, WatchdogConfig())\nasyncio.create_task(watchdog.run())\n\n# Watchdog background loop\nasync def run(self):\n    while True:\n        await asyncio.sleep(60)  # Check every minute\n        health = await self.check_health()\n        if health == HealthStatus.DEGRADED:\n            await self.attempt_recovery(self.recovery_attempts + 1)\n            self.recovery_attempts += 1\n```\n\n### Scanner Enhancements\nAdd methods to scanner.py:\n- `get_health_status()` - Current scanner state\n- `get_error_count_last_hour()` - Recent error count\n- `force_restart()` - Clean restart of scan loop\n- `get_adapter_info()` - Adapter details for diagnostics\n\n### Logging and Diagnostics\nComprehensive logging for troubleshooting:\n```python\nlogger.info(f\"Watchdog: Health check - {health.name}\")\nlogger.warning(f\"Watchdog: Attempting recovery level {level}\")\nlogger.error(f\"Watchdog: Recovery failed - {error}\")\n```\n\n## Configuration UI\nSettings on System page:\n- Enable/disable watchdog\n- Reading timeout threshold\n- Recovery cooldown period\n- Email/push notification on recovery attempts\n\n## Implementation Phases\n1. **Phase 1**: Health monitoring and detection\n2. **Phase 2**: Soft reset and adapter reset recovery\n3. **Phase 3**: Service reset and USB reset\n4. **Phase 4**: Configuration UI and notifications\n\n## Estimated Effort\n20-30 hours total\n\n## Success Criteria\n- Automatic recovery from common BLE failures\n- No manual intervention needed for typical issues\n- Clear logging of recovery attempts\n- User notification when manual intervention required\n- Configurable thresholds for different environments","status":"open","priority":2,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:30:35.445846612+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:30:35.445846612+11:00"}
{"id":"tilt_ui-lxn","title":"Research: Push Notification Infrastructure Requirements","description":"## Summary\nResearch and document the infrastructure requirements for implementing Web Push notifications in BrewSignal.\n\n## Research Questions\n\n### 1. VAPID Keys\n- How to generate VAPID key pairs\n- Where to store keys (env vars? config?)\n- Key rotation strategy (if needed)\n\n### 2. Web Push API\n- Browser support matrix (Chrome, Firefox, Safari, mobile)\n- pywebpush library capabilities and limitations\n- Message payload size limits\n- Delivery guarantees and retry behavior\n\n### 3. SvelteKit Service Worker\n- @vite-pwa/sveltekit vs manual service worker\n- Push event handling in service worker\n- Notification permission UX best practices\n- Testing service workers in development\n\n### 4. Database Schema\n- Subscription storage (endpoint, keys)\n- Multi-device support (one user, multiple subscriptions)\n- Subscription cleanup (expired/invalid endpoints)\n\n### 5. Testing Strategy\n- How to test push notifications locally\n- Mock vs real push in development\n- E2E testing approaches\n\n### 6. Security Considerations\n- VAPID key protection\n- Subscription validation\n- Rate limiting to prevent abuse\n\n## Deliverables\n- [ ] Document with recommended approach\n- [ ] Example code snippets for key components\n- [ ] List of dependencies to add\n- [ ] Estimated implementation complexity","status":"open","priority":2,"issue_type":"task","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:32:16.379631623+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:32:16.379631623+11:00"}
{"id":"tilt_ui-og0","title":"Add MPC logging and observability","description":"Log MPC decisions and predictions for debugging and monitoring.\n\n**What to log:**\n- MPC thermal model parameters (heating_rate, cooling_rate, ambient_coeff)\n- Control decisions (heater_on, cooler_on, reason, predicted_temp, cost)\n- Fallback events (when MPC unavailable, falls back to hysteresis)\n\n**How:**\n- logger.info() for key decisions\n- logger.debug() for detailed predictions\n- Consider adding MPC state to get_batch_control_status() for UI visibility\n\n**Location:** backend/temp_controller.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:21.155564426+11:00","updated_at":"2025-12-09T23:11:30.264126503+11:00","closed_at":"2025-12-09T23:11:30.264126503+11:00"}
{"id":"tilt_ui-pbp","title":"Round-trip conversion tests (BrewSignal â†” BeerJSON)","description":"Create comprehensive tests for lossless conversion between BrewSignal and BeerJSON formats.\n\n## Test Goal\nEnsure **lossless round-trip** conversion:\n```\nBeerJSON â†’ BrewSignal â†’ BeerJSON (must be identical)\nBrewSignal â†’ BeerJSON â†’ BrewSignal (must be identical)\n```\n\n## Test Cases\n\n### 1. BeerJSON â†’ BrewSignal â†’ BeerJSON\n```python\ndef test_beerjson_roundtrip():\n    # Load original BeerJSON\n    original = load_beerjson_recipe('test_data/original.json')\n    \n    # Convert to BrewSignal\n    brewsignal = beerjson_to_brewsignal(original)\n    \n    # Convert back to BeerJSON\n    result = brewsignal_to_beerjson(brewsignal)\n    \n    # Assert identical (deep equality)\n    assert_deep_equal(original, result)\n```\n\n### 2. BrewSignal â†’ BeerJSON â†’ BrewSignal\n```python\ndef test_brewsignal_roundtrip():\n    # Load original BrewSignal\n    original = load_brewsignal_recipe('examples/recipes/west-coast-ipa-complete.brewsignal')\n    \n    # Convert to BeerJSON\n    beerjson = brewsignal_to_beerjson(original)\n    \n    # Convert back to BrewSignal\n    result = beerjson_to_brewsignal(beerjson)\n    \n    # Assert identical\n    assert_deep_equal(original, result)\n```\n\n### 3. Database Round-Trip\n```python\nasync def test_database_roundtrip():\n    # Import BrewSignal recipe to DB\n    recipe = await import_brewsignal_recipe(brewsignal_data)\n    \n    # Export from DB as BrewSignal\n    exported = await export_recipe_as_brewsignal(recipe.id)\n    \n    # Assert identical to original\n    assert_deep_equal(brewsignal_data, exported)\n```\n\n## Test Data\n\n### Minimal Recipe\n- Use `examples/recipes/minimal-pale-ale.brewsignal`\n- Test required fields only\n- Verify no data loss on minimal input\n\n### Complete Recipe\n- Use `examples/recipes/west-coast-ipa-complete.brewsignal`\n- Test all optional fields\n- Test BrewSignal extensions\n\n### Complex BeerJSON\n- Multi-hop schedule (mash, boil, whirlpool, dry hop)\n- Multi-stage fermentation\n- Water chemistry\n- Mash schedule\n- All optional fields populated\n\n### Edge Cases\n- [ ] Empty arrays (no hops, no fermentables)\n- [ ] Null/missing optional fields\n- [ ] Maximum field values\n- [ ] Minimum field values\n- [ ] Special characters in names\n- [ ] Unicode characters (emoji in notes)\n\n## Extension Preservation\n\n### BrewSignal Extensions\n- [ ] Fermentation tracking config preserved\n- [ ] Batch defaults preserved\n- [ ] Yeast management config preserved\n\n### BeerJSON Extensions\n- [ ] Unknown BeerJSON fields stored in format_extensions\n- [ ] Preserved on round-trip export\n- [ ] Not lost during conversion\n\n## File Location\n`backend/tests/test_recipe_conversion.py`\n\n## Tasks\n- [ ] Create test file with pytest fixtures\n- [ ] Test BeerJSON â†’ BrewSignal â†’ BeerJSON\n- [ ] Test BrewSignal â†’ BeerJSON â†’ BrewSignal\n- [ ] Test database import/export round-trip\n- [ ] Test with minimal recipe\n- [ ] Test with complete recipe\n- [ ] Test with complex BeerJSON\n- [ ] Test edge cases (empty arrays, nulls, etc.)\n- [ ] Test extension preservation\n- [ ] Test field mapping (og â†” original_gravity)\n- [ ] Test unit unwrapping/wrapping\n- [ ] Add assertion helpers (deep_equal with tolerance for floats)\n\n## Assertion Helpers\n```python\ndef assert_deep_equal(a: dict, b: dict, path: str = \"root\"):\n    \"\"\"Deep equality with float tolerance and helpful error messages.\"\"\"\n    # Compare keys\n    assert set(a.keys()) == set(b.keys()), f\"{path}: Key mismatch\"\n    \n    for key in a.keys():\n        val_a = a[key]\n        val_b = b[key]\n        current_path = f\"{path}.{key}\"\n        \n        if isinstance(val_a, dict):\n            assert_deep_equal(val_a, val_b, current_path)\n        elif isinstance(val_a, list):\n            assert len(val_a) == len(val_b), f\"{current_path}: List length mismatch\"\n            for i, (item_a, item_b) in enumerate(zip(val_a, val_b)):\n                assert_deep_equal(item_a, item_b, f\"{current_path}[{i}]\")\n        elif isinstance(val_a, float):\n            assert abs(val_a - val_b) \u003c 0.0001, f\"{current_path}: {val_a} != {val_b}\"\n        else:\n            assert val_a == val_b, f\"{current_path}: {val_a} != {val_b}\"\n```\n\n## Dependencies\n- Requires: tilt_ui-4hu (conversion functions)\n\n## Acceptance Criteria\n- All round-trip tests pass\n- No data loss in conversions\n- Extensions preserved correctly\n- Edge cases handled gracefully\n- Test coverage \u003e 90% for conversion code","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T09:36:28.4210199+11:00","updated_at":"2025-12-10T11:45:48.687190081+11:00","closed_at":"2025-12-10T11:45:48.687190081+11:00","dependencies":[{"issue_id":"tilt_ui-pbp","depends_on_id":"tilt_ui-4hu","type":"blocks","created_at":"2025-12-10T09:37:59.555512563+11:00","created_by":"daemon","metadata":"{}"}]}
{"id":"tilt_ui-pzu","title":"Build frontend UI for recipe management","description":"Create comprehensive frontend UI for the recipe CRUD system implemented in PR #87 (now merged).\n\n**Backend Capabilities (Already Built):**\nâœ… Multi-format recipe import (BeerXML, BeerJSON, Brewfather JSON)\nâœ… Full CRUD API endpoints (GET, POST, PUT, DELETE)\nâœ… BeerJSON 2.06 schema support\nâœ… Recipe serializer for BeerJSON output\nâœ… Database migrations complete\n\n**PR Reference:** https://github.com/machug/brewsignal/pull/87\n\n---\n\n## Frontend Work Required\n\n### 1. Recipe List Page (`/recipes`)\n- [ ] Table/card view of all recipes\n- [ ] Filter/search by name, style\n- [ ] Sort by name, date created\n- [ ] Quick actions: View, Edit, Delete\n- [ ] Import button (multi-format)\n\n### 2. Recipe Detail Page (`/recipes/[id]`)\n- [ ] Display all BeerJSON fields:\n  - Name, style, brewer, batch size\n  - OG, FG, ABV, IBU, color (SRM)\n  - Boil time, efficiency\n  - Carbonation volumes\n- [ ] Show ingredients (fermentables, hops, cultures/yeasts, misc)\n- [ ] Display mash/fermentation/packaging steps\n- [ ] Edit/Delete actions\n- [ ] \"Create Batch from Recipe\" button\n\n### 3. Recipe Import UI\n- [ ] Multi-format file picker (.xml for BeerXML, .json for BeerJSON/Brewfather)\n- [ ] Format detection help text\n- [ ] Import progress/error feedback\n- [ ] Handle array error responses from backend\n\n### 4. Recipe Create/Edit Forms\n- [ ] Basic info: name, style, brewer, batch size\n- [ ] Gravity/alcohol: OG, FG, ABV\n- [ ] Color/bitterness: SRM, IBU\n- [ ] Brewing params: boil time, efficiency, carbonation\n- [ ] Ingredients sections (fermentables, hops, cultures, misc)\n- [ ] Mash/fermentation/packaging steps\n- [ ] Format extensions field (JSON)\n- [ ] Field validation (updateRecipe uses whitelist)\n\n### 5. Integration Points\n- [ ] Update batch create flow to select from recipes\n- [ ] Link recipe detail to associated batches\n- [ ] Handle temperature unit conversion (C/F)\n- [ ] Use existing TailwindCSS styling conventions\n\n---\n\n## Technical Notes\n\n**API Endpoints Available:**\n- GET /api/recipes - List all recipes\n- GET /api/recipes/{id} - Get recipe details\n- POST /api/recipes - Create recipe\n- PUT /api/recipes/{id} - Update recipe (uses field whitelist)\n- DELETE /api/recipes/{id} - Delete recipe\n- POST /api/recipes/import - Import from file (BeerXML/BeerJSON/Brewfather)\n- GET /api/recipes/{id}/beerjson - Export as BeerJSON\n\n**Frontend API Functions (Already Created):**\n```typescript\n// From frontend/src/lib/api.ts\ncreateRecipe(data: RecipeCreate): Promise\u003cRecipeResponse\u003e\nupdateRecipe(id: number, data: RecipeUpdate): Promise\u003cRecipeResponse\u003e\nimportRecipe(file: File): Promise\u003cRecipeResponse\u003e\n```\n\n**BeerJSON Field Names:**\n- Use `og`, `fg`, `abv` (NOT og_target, fg_target)\n- Use `color_srm`, `batch_size_liters`\n- Cultures table (was yeasts)\n\n**Security:**\n- updateRecipe uses field whitelist (can't update arbitrary fields)\n- Handle both string and array error formats\n\n---\n\n## Acceptance Criteria\n- [ ] Can view list of all recipes\n- [ ] Can import recipe from BeerXML, BeerJSON, or Brewfather JSON\n- [ ] Can view recipe details with all fields\n- [ ] Can create new recipe manually\n- [ ] Can edit existing recipe (respects backend field whitelist)\n- [ ] Can delete recipe\n- [ ] Can create batch from recipe (integration point)\n- [ ] Temperature units respect user preferences (C/F)\n- [ ] Error handling for import failures\n- [ ] Responsive design (mobile-friendly)\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-09T10:52:36.617912412+11:00","updated_at":"2025-12-09T11:35:47.274967461+11:00","closed_at":"2025-12-09T11:35:47.274970341+11:00"}
{"id":"tilt_ui-r43","title":"Test MPC integration with real batch data","description":"Validate MPC integration using production batch data to ensure it prevents overshoot.\n\n**Test scenarios:**\n1. Heater-only mode (no cooler)\n2. Dual-mode (heater + cooler)\n3. MPC disabled (should use basic hysteresis)\n4. Insufficient history (should fall back gracefully)\n\n**Success criteria:**\n- No overshoot beyond Â±0.5Â°C of target\n- Smooth transitions (no rapid cycling)\n- Falls back to hysteresis when MPC unavailable\n\n**Location:** Manual testing on RPi deployment","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:22.163280576+11:00","updated_at":"2025-12-09T23:11:30.264595883+11:00","closed_at":"2025-12-09T23:11:30.264595883+11:00"}
{"id":"tilt_ui-so8","title":"Quick Actions from Dashboard Cards","description":"## Summary\nAdd action buttons directly to dashboard batch cards, reducing clicks for common operations like adjusting temperature targets, transitioning batch status, or adding notes.\n\n## Motivation\nCurrently, users must navigate to the batch detail page to perform actions. For quick tasks like \"bump the temp up 2 degrees\" or \"mark as conditioning\", this creates unnecessary friction. Quick actions enable faster workflows.\n\n## Features\n\n### 1. Temperature Quick Adjust\nOn batch cards with temperature control:\n- Current target display with +/- buttons\n- Quick preset buttons (e.g., \"Diacetyl rest +3Â°\")\n- Click target to enter custom value\n\n### 2. Status Transitions\nQuick buttons for common status changes:\n- Planning â†’ Fermenting (with OG entry)\n- Fermenting â†’ Conditioning\n- Conditioning â†’ Completed\n\n### 3. Quick Notes\n- \"Add note\" button opens inline input\n- Recent note snippet shown on card\n- Links to full notes view\n\n### 4. Control Overrides\nFor temperature control batches:\n- Force heater ON/OFF toggle\n- Force cooler ON/OFF toggle\n- Visual indicator of current state\n\n### 5. Device Actions\n- Unpair device (with confirmation)\n- Recalibrate link\n- View signal strength trend\n\n## Technical Approach\n\n### UI Components\n\n**QuickActions.svelte:**\n```svelte\n\u003cscript\u003e\n    export let batch;\n    let showTempAdjust = $state(false);\n    let showQuickNote = $state(false);\n\u003c/script\u003e\n\n\u003cdiv class=\"quick-actions flex gap-2 mt-2\"\u003e\n    \u003c!-- Temperature adjust --\u003e\n    {#if batch.target_temp !== null}\n        \u003cdiv class=\"temp-control\"\u003e\n            \u003cbutton onclick={() =\u003e adjustTemp(-1)}\u003e-\u003c/button\u003e\n            \u003cspan class=\"target\"\u003e{batch.target_temp}Â°\u003c/span\u003e\n            \u003cbutton onclick={() =\u003e adjustTemp(+1)}\u003e+\u003c/button\u003e\n        \u003c/div\u003e\n    {/if}\n    \n    \u003c!-- Status transition --\u003e\n    {#if batch.status === 'fermenting'}\n        \u003cbutton \n            class=\"btn-sm\"\n            onclick={() =\u003e transitionStatus('conditioning')}\n        \u003e\n            â†’ Conditioning\n        \u003c/button\u003e\n    {/if}\n    \n    \u003c!-- Quick note --\u003e\n    \u003cbutton \n        class=\"btn-sm btn-outline\"\n        onclick={() =\u003e showQuickNote = true}\n    \u003e\n        ğŸ“ Note\n    \u003c/button\u003e\n\u003c/div\u003e\n\n{#if showQuickNote}\n    \u003cQuickNoteInput \n        batchId={batch.id} \n        onClose={() =\u003e showQuickNote = false}\n    /\u003e\n{/if}\n```\n\n**TempQuickAdjust.svelte:**\n```svelte\n\u003cscript\u003e\n    export let batchId;\n    export let currentTarget;\n    \n    async function adjustTemp(delta: number) {\n        const newTarget = currentTarget + delta;\n        await fetch(`/api/batches/${batchId}`, {\n            method: 'PATCH',\n            body: JSON.stringify({ target_temp: newTarget })\n        });\n        // Optimistic update\n        currentTarget = newTarget;\n    }\n\u003c/script\u003e\n\n\u003cdiv class=\"inline-flex items-center bg-gray-100 rounded\"\u003e\n    \u003cbutton \n        class=\"px-2 py-1 hover:bg-gray-200\"\n        onclick={() =\u003e adjustTemp(-1)}\n    \u003e\n        âˆ’\n    \u003c/button\u003e\n    \u003cspan class=\"px-2 font-mono\"\u003e{currentTarget}Â°\u003c/span\u003e\n    \u003cbutton \n        class=\"px-2 py-1 hover:bg-gray-200\"\n        onclick={() =\u003e adjustTemp(1)}\n    \u003e\n        +\n    \u003c/button\u003e\n\u003c/div\u003e\n```\n\n**QuickNoteInput.svelte:**\n```svelte\n\u003cscript\u003e\n    export let batchId;\n    export let onClose;\n    \n    let note = $state('');\n    \n    async function saveNote() {\n        await fetch(`/api/batches/${batchId}/events`, {\n            method: 'POST',\n            body: JSON.stringify({\n                event_type: 'note',\n                title: note.slice(0, 50),\n                content: note\n            })\n        });\n        onClose();\n    }\n\u003c/script\u003e\n\n\u003cdiv class=\"mt-2 p-2 bg-gray-50 rounded\"\u003e\n    \u003cinput \n        type=\"text\"\n        placeholder=\"Add a quick note...\"\n        bind:value={note}\n        class=\"w-full px-2 py-1 border rounded\"\n        onkeydown={(e) =\u003e e.key === 'Enter' \u0026\u0026 saveNote()}\n    /\u003e\n    \u003cdiv class=\"flex gap-2 mt-1\"\u003e\n        \u003cbutton class=\"btn-sm\" onclick={saveNote}\u003eSave\u003c/button\u003e\n        \u003cbutton class=\"btn-sm btn-outline\" onclick={onClose}\u003eCancel\u003c/button\u003e\n    \u003c/div\u003e\n\u003c/div\u003e\n```\n\n### Dashboard Card Updates\n\n**BatchCard.svelte modifications:**\n```svelte\n\u003c!-- Add to existing card --\u003e\n\u003cdiv class=\"card-body\"\u003e\n    \u003c!-- Existing content --\u003e\n    \u003ch3\u003e{batch.name}\u003c/h3\u003e\n    \u003cp\u003eSG: {latestReading.sg}\u003c/p\u003e\n    \u003cp\u003eTemp: {latestReading.temp}Â°\u003c/p\u003e\n    \n    \u003c!-- NEW: Quick actions --\u003e\n    \u003cQuickActions {batch} /\u003e\n\u003c/div\u003e\n```\n\n### API Optimizations\nEnsure these endpoints support partial updates:\n- PATCH /api/batches/{id} - Update target_temp, status\n- POST /api/batches/{id}/events - Add note (lightweight)\n- PUT /api/control/{batch_id}/override - Set force override\n\n### Mobile Considerations\n- Touch-friendly button sizes (min 44x44px)\n- Swipe actions (future enhancement)\n- Confirmation dialogs for destructive actions\n\n## UI Design\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  American IPA #12                          ğŸŸ¢ Fermenting     â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  SG: 1.024  â”‚  Temp: 67.2Â°F  â”‚  Day 5                       â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  Target: [âˆ’] 68Â°F [+]    [â†’ Conditioning]    [ğŸ“ Note]      â”‚\nâ”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\nâ”‚  Last note: \"Dry hopped 2oz Citra\" (2h ago)                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Implementation Phases\n1. **Phase 1**: Temperature quick adjust (+/- buttons)\n2. **Phase 2**: Status transition buttons\n3. **Phase 3**: Quick note input\n4. **Phase 4**: Control override toggles\n\n## Estimated Effort\n12-18 hours total\n\n## Success Criteria\n- Adjust temp target in 1 click\n- Transition batch status in 2 clicks\n- Add note without leaving dashboard\n- Actions reflect immediately (optimistic updates)\n- Mobile-friendly touch targets\n- No accidental actions (confirmation for destructive operations)","status":"open","priority":3,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:30:38.140276989+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:30:38.140276989+11:00"}
{"id":"tilt_ui-vl5","title":"Add MPC configuration settings","description":"Add config settings to enable/disable MPC and configure MPC parameters (horizon, learning window, etc). This allows users to toggle MPC on/off and tune behavior.\n\n**Config fields:**\n- mpc_enabled (bool, default=False for backward compat)\n- mpc_horizon_hours (float, default=4.0)\n- mpc_learning_window_hours (float, default=24.0)\n\n**Location:** backend/database.py config migrations + backend/routers/config.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:16.101929656+11:00","updated_at":"2025-12-09T23:11:30.262001074+11:00","closed_at":"2025-12-09T23:11:30.262001074+11:00"}
{"id":"tilt_ui-vpd","title":"Modify control_batch_temperature to use MPC compute_action","description":"Replace basic hysteresis thresholds with MPC compute_action() when MPC is enabled and model is available.\n\n**Logic flow:**\n1. Check if mpc_enabled config is true\n2. Get or create MPC controller for batch\n3. If model not learned yet, learn from history\n4. Call mpc.compute_action(current_temp, target_temp, ambient_temp, heater_state, cooler_state)\n5. Use returned heater_on/cooler_on decisions\n6. Fall back to basic hysteresis if MPC unavailable or fails\n\n**Location:** backend/temp_controller.py:control_batch_temperature()","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-09T21:11:19.89570758+11:00","updated_at":"2025-12-09T23:11:30.263686693+11:00","closed_at":"2025-12-09T23:11:30.263686693+11:00"}
{"id":"tilt_ui-wj8","title":"Progressive Web App (PWA) with Offline Support","description":"## Summary\nConvert BrewSignal to a Progressive Web App with offline support, enabling mobile installation and access to fermentation data even without network connectivity.\n\n## Motivation\nBrewers frequently check fermentation status from their phones while away from their computer. A PWA provides:\n- \"Add to Home Screen\" for native app-like experience\n- Offline access to last known readings\n- Faster load times via service worker caching\n- Push notification support (ties into notification feature)\n\n## Features\n\n### 1. Installable App\n- Web app manifest for \"Add to Home Screen\"\n- App icon and splash screen\n- Standalone display mode (no browser chrome)\n\n### 2. Offline Support\n- Cache static assets (JS, CSS, images)\n- Cache last known device readings\n- Cache batch list and details\n- Show \"offline\" indicator when disconnected\n- Queue actions for sync when online\n\n### 3. Background Sync\n- Sync data when network restored\n- Update cached readings\n- Submit queued notes/actions\n\n### 4. Performance\n- Pre-cache critical routes\n- Stale-while-revalidate for API data\n- Lazy load non-critical features\n\n## Technical Approach\n\n### SvelteKit PWA Configuration\n\n**vite.config.js:**\n```javascript\nimport { sveltekit } from '@sveltejs/kit/vite';\nimport { SvelteKitPWA } from '@vite-pwa/sveltekit';\n\nexport default {\n    plugins: [\n        sveltekit(),\n        SvelteKitPWA({\n            registerType: 'autoUpdate',\n            manifest: {\n                name: 'BrewSignal',\n                short_name: 'BrewSignal',\n                description: 'Fermentation Monitoring Dashboard',\n                theme_color: '#f59e0b',\n                background_color: '#1f2937',\n                display: 'standalone',\n                icons: [\n                    {\n                        src: '/icons/icon-192.png',\n                        sizes: '192x192',\n                        type: 'image/png'\n                    },\n                    {\n                        src: '/icons/icon-512.png',\n                        sizes: '512x512',\n                        type: 'image/png'\n                    }\n                ]\n            },\n            workbox: {\n                globPatterns: ['**/*.{js,css,html,ico,png,svg,woff,woff2}'],\n                runtimeCaching: [\n                    {\n                        urlPattern: /^https:\\/\\/.*\\/api\\/devices\\/readings/,\n                        handler: 'StaleWhileRevalidate',\n                        options: {\n                            cacheName: 'readings-cache',\n                            expiration: {\n                                maxEntries: 50,\n                                maxAgeSeconds: 60 * 60 // 1 hour\n                            }\n                        }\n                    },\n                    {\n                        urlPattern: /^https:\\/\\/.*\\/api\\/batches/,\n                        handler: 'StaleWhileRevalidate',\n                        options: {\n                            cacheName: 'batches-cache',\n                            expiration: {\n                                maxEntries: 100,\n                                maxAgeSeconds: 60 * 60 * 24 // 24 hours\n                            }\n                        }\n                    }\n                ]\n            }\n        })\n    ]\n};\n```\n\n### Service Worker Strategy\n\n**Caching Strategies:**\n- **Static assets**: Cache-first (CSS, JS, fonts)\n- **API readings**: Stale-while-revalidate (show cached, fetch fresh)\n- **Batch data**: Network-first with cache fallback\n- **Charts**: Cache raw data, render client-side\n\n**Offline Data Storage:**\n```javascript\n// lib/offline-store.ts\nimport { openDB } from 'idb';\n\nconst db = await openDB('brewsignal-offline', 1, {\n    upgrade(db) {\n        db.createObjectStore('readings', { keyPath: 'device_id' });\n        db.createObjectStore('batches', { keyPath: 'id' });\n        db.createObjectStore('pending-actions', { autoIncrement: true });\n    }\n});\n\nexport async function cacheReading(deviceId: string, reading: Reading) {\n    await db.put('readings', { device_id: deviceId, ...reading });\n}\n\nexport async function getCachedReadings(): Promise\u003cReading[]\u003e {\n    return await db.getAll('readings');\n}\n\nexport async function queueAction(action: PendingAction) {\n    await db.add('pending-actions', action);\n}\n```\n\n### Offline UI Indicators\n\n**OfflineStatus.svelte:**\n```svelte\n\u003cscript\u003e\n    let online = $state(navigator.onLine);\n    \n    $effect(() =\u003e {\n        const handleOnline = () =\u003e online = true;\n        const handleOffline = () =\u003e online = false;\n        \n        window.addEventListener('online', handleOnline);\n        window.addEventListener('offline', handleOffline);\n        \n        return () =\u003e {\n            window.removeEventListener('online', handleOnline);\n            window.removeEventListener('offline', handleOffline);\n        };\n    });\n\u003c/script\u003e\n\n{#if !online}\n    \u003cdiv class=\"fixed bottom-0 left-0 right-0 bg-yellow-500 text-center py-2\"\u003e\n        âš ï¸ You're offline. Showing cached data.\n    \u003c/div\u003e\n{/if}\n```\n\n### Background Sync\n\n**sw.js additions:**\n```javascript\nself.addEventListener('sync', event =\u003e {\n    if (event.tag === 'sync-actions') {\n        event.waitUntil(syncPendingActions());\n    }\n});\n\nasync function syncPendingActions() {\n    const db = await openDB('brewsignal-offline', 1);\n    const actions = await db.getAll('pending-actions');\n    \n    for (const action of actions) {\n        try {\n            await fetch(action.url, {\n                method: action.method,\n                body: JSON.stringify(action.body)\n            });\n            await db.delete('pending-actions', action.id);\n        } catch (e) {\n            // Will retry on next sync\n        }\n    }\n}\n```\n\n### App Icons\nCreate icon set:\n- `/static/icons/icon-72.png`\n- `/static/icons/icon-96.png`\n- `/static/icons/icon-128.png`\n- `/static/icons/icon-144.png`\n- `/static/icons/icon-152.png`\n- `/static/icons/icon-192.png`\n- `/static/icons/icon-384.png`\n- `/static/icons/icon-512.png`\n\n## What Works Offline\n- View last known readings for all devices\n- Browse batch list and details\n- View cached charts (recent data)\n- Add notes (queued for sync)\n- Change settings (queued for sync)\n\n## What Requires Online\n- Real-time WebSocket updates\n- Temperature control changes\n- Creating new batches\n- Full chart history (if not cached)\n\n## Implementation Phases\n1. **Phase 1**: PWA manifest and basic service worker\n2. **Phase 2**: Static asset caching\n3. **Phase 3**: API response caching (readings, batches)\n4. **Phase 4**: Offline indicators and action queuing\n5. **Phase 5**: Background sync\n\n## Estimated Effort\n25-35 hours total\n\n## Success Criteria\n- App installable on iOS/Android home screens\n- Last known readings visible offline\n- Batch details accessible offline\n- Clear indication of offline status\n- Actions sync when connection restored\n- Lighthouse PWA score \u003e 90","status":"open","priority":3,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:30:37.001813736+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:30:37.001813736+11:00"}
{"id":"tilt_ui-xlz","title":"AI Brewing Assistant with Recipe Generation","description":"## Overview\nAdd an AI-powered brewing assistant to help users create recipes, troubleshoot fermentation issues, and get brewing advice.\n\n## Features\n\n### 1. LLM Backend Options\n- **Local SLM**: Support for local small language models (Ollama, llama.cpp)\n  - Privacy-first option (no data leaves user's network)\n  - Works offline\n  - Models: Llama 3, Mistral, Phi-3, etc.\n  \n- **Cloud LLM APIs**: Optional integration with commercial APIs\n  - OpenAI (GPT-4, GPT-3.5)\n  - Anthropic (Claude)\n  - DeepSeek\n  - User provides their own API key\n  - Stored securely in app config\n\n### 2. Recipe Generation from Prompts\n- Natural language recipe creation\n- Examples:\n  - \"Create a Pliny the Elder clone for my 5-gallon system\"\n  - \"Design a hazy IPA with Citra and Mosaic hops\"\n  - \"Make a Belgian Tripel targeting 9% ABV\"\n  \n- **Context-Aware**:\n  - Uses user's equipment profile (batch size, efficiency)\n  - Considers available inventory (if implemented)\n  - Respects system constraints (mash tun capacity, etc.)\n  \n- **Output**: BrewSignal recipe schema (BeerJSON compatible)\n  - Can be imported directly into recipe library\n  - Includes all standard fields (grains, hops, yeast, mash schedule)\n\n### 3. Fermentation Assistant\n- Answer brewing questions\n- Troubleshoot fermentation issues\n  - \"My gravity is stuck at 1.020, what should I do?\"\n  - \"Is this fermentation curve normal?\"\n- Provide style-specific advice\n- Suggest recipe modifications based on historical batch data\n\n### 4. Context Integration\n- Access to user's batch history\n- Current fermentation data (gravity curves, temperature profiles)\n- Recipe library for learning user preferences\n- Equipment profile for accurate calculations\n\n## Technical Considerations\n\n### Backend Architecture\n- New router: \n- Service layer: \n  -  - Abstract LLM interface\n  -  - Ollama/llama.cpp integration\n  -  - API client for OpenAI/Anthropic/DeepSeek\n  -  - Recipe generation logic\n  -  - Structured prompts for recipe generation\n  \n### Configuration\n- Settings page for LLM configuration\n  - Choose backend (local vs cloud)\n  - API key management (encrypted storage)\n  - Model selection\n  - Temperature/creativity controls\n\n### Recipe Schema Output\n- Generate valid BeerJSON 2.0 format\n- Include calculated values (OG, FG, IBU, SRM, ABV)\n- Validate against schema before presenting to user\n- Allow user to review/modify before saving\n\n### UI Components\n- Chat interface for assistant\n- Recipe generation form with prompt input\n- Preview pane for generated recipes\n- One-click import to recipe library\n\n## Dependencies\n- LLM integration library (e.g., LangChain, LiteLLM for unified API)\n- Ollama server (optional, for local LLM)\n- Recipe calculation engine (reuse existing BrewSignal logic)\n\n## Future Enhancements\n- Multi-turn conversation for recipe refinement\n- Learn from user's successful batches\n- Suggest recipe adjustments based on fermentation telemetry\n- Batch prediction (\"How will this recipe turn out based on my history?\")\n- Integration with ingredients database (when available)\n\n## Security \u0026 Privacy\n- API keys encrypted at rest\n- Local LLM option for privacy-conscious users\n- User data never sent to cloud without explicit consent\n- Rate limiting for API calls to prevent cost overruns","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-09T20:49:49.775721886+11:00","updated_at":"2025-12-09T20:49:49.775721886+11:00"}
{"id":"tilt_ui-xmv","title":"Fix type coercion security bypass (CVSS 7.5)","description":"Pydantic auto-converts strings to floats, bypassing type safety. Add @field_validator(mode='before') to reject non-numeric types. See todo 002.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-10T11:32:08.891258349+11:00","updated_at":"2025-12-10T11:36:27.253919919+11:00","closed_at":"2025-12-10T11:36:27.253919919+11:00"}
{"id":"tilt_ui-yt6","title":"Fix temperature overshoot with asymmetric hysteresis","description":"## Problem\nCurrent symmetric hysteresis causes 1Â°C overshoot:\n- Heater ON at target - 1Â°C (19Â°C)\n- Heater OFF at target + 1Â°C (21Â°C) â† overshoots by 1Â°C\n\n## Solution\nUse asymmetric hysteresis - turn OFF at target instead of target + hysteresis:\n- Heater ON at target - hysteresis (19Â°C)\n- Heater OFF at target (20Â°C) â† no overshoot\n\n## Implementation\nChange 2 lines in backend/temp_controller.py:\n\n```python\n# Line 413-414 (heating)\nheat_on_threshold = round(target_temp - hysteresis, 1)\nheat_off_threshold = round(target_temp, 1)  # Changed from target_temp + hysteresis\n\n# Line 446-447 (cooling) \ncool_on_threshold = round(target_temp + hysteresis, 1)\ncool_off_threshold = round(target_temp, 1)  # Changed from target_temp - hysteresis\n```\n\n## Testing\n- Deploy to RPi\n- Monitor one batch through full fermentation\n- Verify temperature stays within Â±0.5Â°C of target\n\n## Rollback\nIf this causes issues, revert to symmetric hysteresis (restore + hysteresis)\n\n## Related\n- Issue #69 - original overshoot problem\n- MPC integration deferred until this simpler approach tested","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-09T23:11:31.13656325+11:00","updated_at":"2025-12-09T23:15:26.724352427+11:00","closed_at":"2025-12-09T23:15:26.724352427+11:00"}
{"id":"tilt_ui-yzw","title":"Surface ML Predictions in UI","description":"## Summary\nMake existing ML pipeline predictions visible and actionable in the frontend. The backend already calculates fermentation completion estimates, FG predictions, confidence scores, and anomaly detection - this feature surfaces that intelligence to users.\n\n## Motivation\nThe ML pipeline in `/backend/ml/` represents significant investment - Kalman filtering, curve fitting, anomaly detection. But these outputs are minimally exposed in the UI. Users see raw readings when they really want answers: \"When will this be done?\" and \"Is everything okay?\"\n\n## Features to Implement\n\n### 1. Fermentation Progress Card (Batch Detail Page)\n- Visual progress bar showing fermentation completion percentage\n- Estimated completion date/time (\"FG expected in ~3 days\")\n- Projected final gravity with uncertainty range (\"1.012 Â±0.002\")\n- Current attenuation percentage\n\n### 2. Confidence Indicators on Readings\n- Badge/icon when reading confidence \u003c 0.8\n- Tooltip explaining why confidence is low\n- Color-coded readings based on confidence level\n\n### 3. Fermentation Velocity Chart\n- New chart option showing sg_rate (already calculated)\n- Color gradient: active fermentation (green) â†’ slowing (yellow) â†’ complete (gray)\n- Overlay on main gravity chart or separate panel\n\n### 4. Anomaly Visualization\n- Visual markers on chart where is_anomaly = true\n- Expandable panel showing anomaly_reasons\n- Timeline of detected anomalies with timestamps\n\n### 5. Dashboard Summary\n- Quick status for each active batch: \"Fermenting actively\" / \"Slowing down\" / \"Appears complete\"\n- Days remaining estimate on batch cards\n\n## Data Already Available (from ML pipeline)\nFrom Reading model:\n- `sg_filtered`, `temp_filtered` - Kalman filtered values\n- `confidence` - Reading quality (0.0-1.0)  \n- `sg_rate`, `temp_rate` - Derivatives (change per hour)\n- `is_anomaly`, `anomaly_score`, `anomaly_reasons` - Anomaly detection\n- `predicted_fg`, `predicted_completion_time` - Curve fitting predictions\n\n## Technical Approach\n\n### Frontend Components\n1. `FermentationProgress.svelte` - Progress card with predictions\n2. `ConfidenceBadge.svelte` - Indicator for low-confidence readings\n3. `VelocityChart.svelte` - sg_rate visualization using uPlot\n4. `AnomalyMarker.svelte` - Chart overlay for anomalies\n5. Update `BatchCard.svelte` with status summary\n\n### Backend Changes (minimal)\n- Ensure predictions are included in WebSocket broadcasts (may already be)\n- Add endpoint for prediction history if needed for charts\n\n### UI/UX Considerations\n- Don't overwhelm users with data - progressive disclosure\n- Predictions should be clearly labeled as estimates\n- Explain uncertainty ranges in user-friendly terms\n- Mobile-responsive design for all new components\n\n## Implementation Phases\n1. **Phase 1**: Fermentation progress card with completion estimate\n2. **Phase 2**: Confidence indicators on readings  \n3. **Phase 3**: Velocity chart addition\n4. **Phase 4**: Anomaly visualization\n\n## Estimated Effort\n20-30 hours total (data exists, primarily frontend work)\n\n## Success Criteria\n- Users can see \"when will fermentation be done\" without manual calculation\n- Low-confidence readings are visually distinguished\n- Anomalies are surfaced proactively, not hidden in data\n- Predictions update in real-time as new readings arrive","status":"in_progress","priority":1,"issue_type":"feature","owner":"hugh@hughtec.com","created_at":"2026-01-15T19:28:06.512295988+11:00","created_by":"Hugh McIntyre","updated_at":"2026-01-15T19:38:14.815664905+11:00"}
{"id":"tilt_ui-zv4","title":"Update documentation for BrewSignal Recipe Format v1.0","description":"Update project documentation to reference the new BrewSignal Recipe Format v1.0.\n\n## Files to Update\n\n### 1. CLAUDE.md (Project Instructions)\n\nAdd section after \"Recipe \u0026 Batch Pydantic Schemas\":\n\n```markdown\n## BrewSignal Recipe Format v1.0\n\nBrewSignal has its own recipe format optimized for fermentation monitoring:\n\n**Specification**: `docs/BREWSIGNAL_RECIPE_FORMAT_V1.md`\n**JSON Schema**: `backend/schemas/brewsignal-recipe-v1.0.schema.json`\n**Examples**: `examples/recipes/`\n\n### Key Differences from BeerJSON\n\n- **Simpler**: Raw numbers instead of unit objects (`og: 1.050` vs `{\"value\": 1.050, \"unit\": \"sg\"}`)\n- **Shorter field names**: `og`, `fg`, `abv` (not `original_gravity`, `final_gravity`, `alcohol_by_volume`)\n- **Fermentation-focused**: Optimized for tracking, not brew day\n- **Extensions**: `brewsignal_extensions` for fermentation tracking, temp control, yeast management\n\n### Format Usage\n\n**Internal storage**: Database uses simple format (matches BrewSignal)\n**API responses**: Pydantic schemas return BrewSignal format (simple, not verbose)\n**Import pipeline**: BeerXML/Brewfather/BeerJSON â†’ BrewSignal â†’ Database\n**Export**: Database â†’ BrewSignal or BeerJSON (for ecosystem compatibility)\n\n### When to Use Which Format\n\n- **BrewSignal format**: Manual recipe creation, API responses, internal storage\n- **BeerJSON format**: Import/export for compatibility with other brewing software\n- **BeerXML format**: Legacy import only (not recommended for new recipes)\n\n### BrewSignal Extensions\n\nUse `format_extensions.brewsignal` in Recipe model for:\n- Fermentation tracking config (OG validation, FG prediction, anomaly detection)\n- Batch defaults (auto-link device, temperature control settings)\n- Yeast management (pitch rates, starter calculations, rehydration)\n\nExample:\n```python\nrecipe = await db.get(Recipe, recipe_id)\nextensions = recipe.format_extensions.get('brewsignal', {})\nfermentation_config = extensions.get('fermentation_tracking', {})\nif fermentation_config.get('fg_prediction', {}).get('enabled'):\n    # Enable ML-based FG prediction\n    pass\n```\n```\n\n### 2. API Documentation (docs/API.md or OpenAPI spec)\n\nAdd new endpoints:\n\n```markdown\n## Recipe Export\n\n**GET** `/api/recipes/{id}/export`\n\nExport recipe in various formats.\n\n**Query Parameters**:\n- `format`: \"brewsignal\" (default), \"beerjson\", \"beerxml\"\n- `include_extensions`: true/false (default: true)\n\n**Response**:\n- Content-Type: `application/vnd.brewsignal.v1+json` (for BrewSignal format)\n- Content-Disposition: `attachment; filename=\"recipe-name-2025-12-09.brewsignal\"`\n\n**Example**:\n```bash\ncurl -O http://localhost:8080/api/recipes/1/export?format=brewsignal\n```\n\n## Recipe Validation\n\n**POST** `/api/recipes/validate`\n\nValidate recipe data before import.\n\n**Request Body**:\n```json\n{\n  \"format\": \"brewsignal\",\n  \"data\": { /* recipe data */ }\n}\n```\n\n**Response (Valid)**:\n```json\n{\n  \"valid\": true,\n  \"warnings\": []\n}\n```\n\n**Response (Invalid)**:\n```json\n{\n  \"valid\": false,\n  \"errors\": [\n    {\"field\": \"recipe.og\", \"error\": \"Value exceeds maximum\"}\n  ]\n}\n```\n```\n\n### 3. README.md (if exists)\n\nAdd section on recipe management:\n\n```markdown\n## Recipe Management\n\nBrewSignal supports multiple recipe formats:\n\n- **Import**: BeerXML, BeerJSON, Brewfather JSON\n- **Native Format**: BrewSignal Recipe Format v1.0 (simplified JSON)\n- **Export**: BrewSignal, BeerJSON, BeerXML\n\n### Recipe Features\n\n- âœ… Multi-format import (auto-detection)\n- âœ… Fermentation-specific extensions (OG validation, FG prediction, anomaly detection)\n- âœ… Temperature control defaults per recipe\n- âœ… Yeast management (pitch rates, starters, rehydration)\n- âœ… Full CRUD via API\n- âœ… Batch-to-recipe linking\n\nSee `docs/BREWSIGNAL_RECIPE_FORMAT_V1.md` for specification.\n```\n\n### 4. Frontend Documentation (if exists)\n\nAdd recipe format info for frontend developers:\n\n```markdown\n## Working with Recipes\n\nThe API returns recipes in BrewSignal format (simple, not verbose BeerJSON):\n\n```typescript\ninterface RecipeResponse {\n  id: number;\n  name: string;\n  og: number;          // Not wrapped in {value, unit}\n  fg: number;\n  abv: number;         // Percent (0-100), not 0-1\n  batch_size_liters: number;\n  // ...\n}\n```\n\n### Recipe Import\n\nSupported formats (auto-detected):\n- `.xml` â†’ BeerXML\n- `.json` â†’ BeerJSON or Brewfather JSON (auto-detected)\n- `.brewsignal` â†’ BrewSignal native format\n\n### Recipe Export\n\n```typescript\n// Export as BrewSignal format\nconst response = await fetch(`/api/recipes/${id}/export?format=brewsignal`);\nconst blob = await response.blob();\ndownloadFile(blob, `${recipeName}.brewsignal`);\n\n// Export as BeerJSON (for other apps)\nconst response = await fetch(`/api/recipes/${id}/export?format=beerjson`);\n```\n```\n\n## Tasks\n\n- [ ] Update CLAUDE.md with BrewSignal format section\n- [ ] Update API documentation (docs/API.md or OpenAPI spec)\n- [ ] Update README.md with recipe features\n- [ ] Update frontend documentation (if exists)\n- [ ] Add format comparison table (BrewSignal vs BeerJSON)\n- [ ] Add migration guide (\"How to convert existing recipes\")\n- [ ] Update architecture diagram (if exists)\n\n## Testing\n\n- [ ] Review all updated docs for accuracy\n- [ ] Check all code examples compile/run\n- [ ] Verify all links work\n- [ ] Check formatting (markdown linting)\n\n## Acceptance Criteria\n\n- CLAUDE.md includes BrewSignal format reference\n- API docs include new endpoints (export, validate)\n- Documentation explains when to use each format\n- Code examples are accurate and complete\n- Links to specification are correct","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T09:37:48.849634433+11:00","updated_at":"2026-01-05T10:00:27.804160194+11:00","closed_at":"2026-01-05T10:00:27.804160194+11:00","close_reason":"Updated format doc to match implementation"}
